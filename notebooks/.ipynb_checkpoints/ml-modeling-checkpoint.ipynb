{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1c1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.decomposition import PCA \n",
    "from scipy import stats\n",
    "import sklearn.utils \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix, f1_score\n",
    "import sys\n",
    "from utils import *\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import random \n",
    "\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cea6d7",
   "metadata": {},
   "source": [
    "# Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34377c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var_datasets = \"HIGH\"\n",
    "NPATH = '../data/datasets/normal/S'+var_datasets+'_obs_MULTslide_2'  #\n",
    "APATH1 = '../data/datasets/anomaly/S'+var_datasets+'_obs_MULTslide_2/adv-low-exf/'\n",
    "APATH2 = '../data/datasets/anomaly/S'+var_datasets+'_obs_MULTslide_2/adv-medium-exf'\n",
    "APATH3 = '../data/datasets/anomaly/S'+var_datasets+'_obs_MULTslide_2/adv-cnc'\n",
    "APATH4 = '../data/datasets/anomaly/S'+var_datasets+'_obs_MULTslide_2/avg-medium-exf'\n",
    "APATH5 = '../data/datasets/anomaly/S'+var_datasets+'_obs_MULTslide_2/avg-cnc'\n",
    "APATH6 = '../data/datasets/anomaly/S'+var_datasets+'_obs_MULTslide_2/api-cnc' \n",
    "\n",
    "datasets_normal = fetch_dataset(NPATH, \"normal\")\n",
    "datasets_anomaly1 = fetch_dataset(APATH1, \"anomaly_nopings\") \n",
    "datasets_anomaly2 = fetch_dataset(APATH2, \"anomaly_nopings\")\n",
    "datasets_anomaly3 = fetch_dataset(APATH3, \"anomaly_nopings\")  \n",
    "datasets_anomaly4 = fetch_dataset(APATH4, \"anomaly_nopings\") \n",
    "datasets_anomaly5 = fetch_dataset(APATH5, \"anomaly_nopings\") \n",
    "datasets_anomaly6 = fetch_dataset(APATH6, \"anomaly_nopings\") \n",
    "\n",
    "#datasets_anomaly4p = fetch_dataset(APATH4, \"anomaly_pings\")\n",
    "#datasets_anomaly5p = fetch_dataset(APATH5, \"anomaly_pings\") \n",
    "#datasets_anomaly2p = fetch_dataset(APATH2, \"anomaly_nopings\") \n",
    "#datasets_anomaly3p = fetch_dataset(APATH3, \"anomaly_nopings\")\n",
    "\n",
    "\n",
    "anomalies_names = []; normal_names = []  \n",
    "all_ds_dict = datasets_normal.copy(); n_scenarios = 0; normal_names = normal_names + list(datasets_normal.keys())\n",
    "all_ds_dict.update(datasets_anomaly1); n_scenarios = n_scenarios + len(datasets_anomaly1); anomalies_names = anomalies_names +  list(datasets_anomaly1.keys())#\n",
    "all_ds_dict.update(datasets_anomaly2); n_scenarios = n_scenarios + len(datasets_anomaly2); anomalies_names = anomalies_names +  list(datasets_anomaly2.keys())###<<<\n",
    "all_ds_dict.update(datasets_anomaly3); n_scenarios = n_scenarios + len(datasets_anomaly3); anomalies_names = anomalies_names +  list(datasets_anomaly3.keys())########\n",
    "all_ds_dict.update(datasets_anomaly4); n_scenarios = n_scenarios + len(datasets_anomaly4); anomalies_names = anomalies_names +  list(datasets_anomaly4.keys())####\n",
    "all_ds_dict.update(datasets_anomaly5); n_scenarios = n_scenarios + len(datasets_anomaly5); anomalies_names = anomalies_names +  list(datasets_anomaly5.keys())####\n",
    "all_ds_dict.update(datasets_anomaly6); n_scenarios = n_scenarios + len(datasets_anomaly6); anomalies_names = anomalies_names +  list(datasets_anomaly6.keys())  #######################allallallallallallallallallallallall####\n",
    "######################$############$####\n",
    "#all_ds_dict.update(datasets_anomaly4p); n_scenarios = n_scenarios + len(datasets_anomaly4p); anomalies_names = anomalies_names +  list(datasets_anomaly4p.keys())####\n",
    "#all_ds_dict.update(datasets_anomaly5p); n_scenarios = n_scenarios + len(datasets_anomaly5p); anomalies_names = anomalies_names +  list(datasets_anomaly5p.keys())####\n",
    "#all_ds_dict.update(datasets_anomaly2p); n_scenarios = n_scenarios + len(datasets_anomaly2p); anomalies_names = anomalies_names +  list(datasets_anomaly2p.keys())####\n",
    "#all_ds_dict.update(datasets_anomaly3p); n_scenarios = n_scenarios + len(datasets_anomaly3p); anomalies_names = anomalies_names +  list(datasets_anomaly3p.keys())####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b93d9",
   "metadata": {},
   "source": [
    "# 2 Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce0f791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#datasets_anomaly = {}\n",
    "#datasets_anomaly.update(datasets_anomaly1)\n",
    "#datasets_anomaly.update(datasets_anomaly2)\n",
    "#datasets_anomaly.update(datasets_anomaly3) #\\1 1..\n",
    "#datasets_anomaly.update(datasets_anomaly4)\n",
    "#datasets_anomaly.update(datasets_anomaly5)##\n",
    "#datasets_anomaly.update(datasets_anomaly4p)\n",
    "#datasets_anomaly.update(datasets_anomaly5p)##\n",
    "#datasets_anomaly.update(datasets_anomaly6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f62660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "52\n",
      "78\n",
      "104\n",
      "130\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "features = datasets_normal['msyn'].shape[1] #print()\n",
    "maxmin = [0]\n",
    "n = 0\n",
    "while n < features:\n",
    "    n = n + 26\n",
    "    if n > features:\n",
    "        n = features\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea675cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_histograms(datasets_normal, datasets_anomaly, \"standard_behaviors.pdf\", min_value=130, max_value=150)      #612162high271451501001523784104515013.{**datasets_anomy_adv_med_exf, **datasets_anomy_avg_med_exf}ssmall/ssmall/sSMALL_6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d673d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datav(min, max, ds):\n",
    "    columns2pick = ds.columns[min:max]  # 8 12\n",
    "    ds = ds[columns2pick.append(pd.Index([ds.columns[-1]]))]\n",
    "    columns2pick = list(columns2pick)\n",
    "    index_vals = ds['label'].astype('category').cat.codes\n",
    "    opacities = [1 if val == 0 else 0.01 for val in index_vals]\n",
    "    colors_vals = ['rgba(52, 113, 235, 1)' if val == 0 else 'rgba(237, 76, 74, 1)' for val in index_vals]\n",
    "    fig = go.Figure(data=go.Splom(\n",
    "                        dimensions=[dict(label=name, values=ds[name]) for name in ds.iloc[:, :-1]],\n",
    "                        text=ds['label'],\n",
    "                        marker=dict(color=colors_vals,\n",
    "                        showscale=False, # colors encode categorical variables\n",
    "                        line_color=None, line_width=0.2, opacity=opacities),\n",
    "                        )) #index='label'index='label'\n",
    "\n",
    "    fig.update_traces(diagonal_visible=False)\n",
    "    fig.update_layout(height = 900, title=\"Scatter matrix for Dataset with a sliding window of 70 minutes\")\n",
    "    fig.show()\n",
    "    \n",
    "    import plotly.io as pio\n",
    "    pio.write_image(fig, 'scatter-pings-70.pdf', width=1080, height=1080) #,scale=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c134383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Audio, display\n",
    "#\n",
    "#def allDone():\n",
    "#  display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))\n",
    "#\n",
    "#allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b15cd3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_ds = pd.concat([all_ds_dict[df].copy() for df in all_ds_dict])\n",
    "\n",
    "#\"\"\" original \"\"\"\n",
    "\n",
    "#datav(103, 105, all_ds); \n",
    "\n",
    "#datav_2d(8, 15, all_ds); datav_2d(16, 23, all_ds); datav_2d(24 , 31, all_ds)\n",
    "#datav_2d(32, 39, all_ds); datav_2d(40, 47, all_ds); datav_2d(48, 55, all_ds)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748222e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity_trim_mean_05_3600\n",
      "pps_upload_mean_2700\n",
      "silence_mean_3600\n"
     ]
    }
   ],
   "source": [
    "all_ds = pd.concat([all_ds_dict[df].copy() for df in all_ds_dict])\n",
    "columns = list(all_ds.keys())[:-1]\n",
    "columns1 = columns.pop(random.randint(0, len(columns)-1))\n",
    "columns2 = columns.pop(random.randint(0, len(columns)-1))\n",
    "columns3 = columns.pop(random.randint(0, len(columns)-1))\n",
    "print(columns1)\n",
    "print(columns2)\n",
    "print(columns3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f22190",
   "metadata": {},
   "source": [
    "# Datasets De-Annotation &  Train, Test set splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb00b72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3132\n",
      "3132\n",
      "(16131, 151)\n",
      "288\n",
      "3\n",
      "181302\n",
      "ANOMALY DATASET SIZE:  (16131, 150)\n",
      "NORMAL  DATASET SIZE:  (16131, 150)\n",
      "iodine-ncat-13sept\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "#### CREATE ILLICIT TEST SET  ####^\n",
    "##################################\n",
    "anomaly_name = anomalies_names[random.randint(0, len(anomalies_names)-1)]\n",
    "test_anomaly = all_ds_dict.pop(anomaly_name)\n",
    "n_scenarios = n_scenarios - 1  \n",
    "\n",
    "y_test_anomaly = test_anomaly['label'].to_numpy()\n",
    "test_anomaly = test_anomaly.drop('label', axis=1) .to_numpy()\n",
    "    \n",
    "\n",
    "#################################\n",
    "#### CREATE OVERALL TEST SET ####\n",
    "#################################   \n",
    "\n",
    "\n",
    "# group all licit captures \n",
    "ds_normal = pd.concat(\n",
    "    [all_ds_dict[df].copy() for df in all_ds_dict if not all_ds_dict[df][\"label\"].all()]\n",
    ") \n",
    "# suffle data\n",
    "ds_normal = shuffle(ds_normal)\n",
    "# create licit data for test set with an euqal amount of licit samples\n",
    "test_normal = ds_normal.sample(n=len(test_anomaly), replace = False)\n",
    "# drop those samples for testing purposes\n",
    "ds_normal = ds_normal.drop(test_normal.index)\n",
    "# create test set\n",
    "y_test_normal = test_normal['label'].to_numpy()\n",
    "test_normal = test_normal.drop('label', axis=1) .to_numpy()\n",
    "x_test = np.vstack((test_anomaly, test_normal))\n",
    "y_test = np.concatenate((y_test_anomaly, y_test_normal))\n",
    "\n",
    "print(len(test_anomaly))    \n",
    "print    ((len(test_normal)))\n",
    "print(ds_normal.shape)\n",
    "\n",
    "#############################\n",
    "#### CREATE TRAINING SET ####\n",
    "############################# \n",
    "\n",
    "n2pick = int(ds_normal.shape[0]/n_scenarios)\n",
    "n2pick_rem = int(ds_normal.shape[0] % n_scenarios)\n",
    "\n",
    "print(n2pick)\n",
    "print(n2pick_rem)\n",
    "\n",
    "ds_anomaly = pd.DataFrame()\n",
    "ds_anomaly_res = pd.DataFrame()\n",
    "ds_anomaly_len = 0\n",
    "for df in all_ds_dict: \n",
    "    #if not all_ds_dict[df][\"label\"].all():\n",
    "    #    print(df)\n",
    "    #    dfs = []    #\n",
    "    if all_ds_dict[df][\"label\"].all():\n",
    "        ds_anomaly_len = ds_anomaly_len + len(all_ds_dict[df])\n",
    "        if n2pick < len(all_ds_dict[df]): \n",
    "            samples = all_ds_dict[df].sample(n=n2pick, replace=False)\n",
    "            ds_anomaly = pd.concat([ds_anomaly, samples]) # *C*C\n",
    "            res = all_ds_dict[df].drop(samples.index)\n",
    "            ds_anomaly_res = pd.concat([ds_anomaly_res, res])\n",
    "        else:\n",
    "             ds_anomaly = pd.concat([ds_anomaly, all_ds_dict[df]])\n",
    "             n2pick_rem = n2pick_rem + (n2pick-len(all_ds_dict[df]))\n",
    "        #\n",
    "print(ds_anomaly_len)            \n",
    "ds_anomaly = pd.concat([ds_anomaly, ds_anomaly_res.sample(n=n2pick_rem, replace=False)]) \n",
    "\n",
    "# save columns just in case...\n",
    "columns = ds_anomaly.columns\n",
    "\n",
    "y_normal = np.array(ds_normal['label'])\n",
    "y_anomaly = np.array(ds_anomaly['label'])\n",
    "\n",
    "#print(y_normalanomaly.any())\n",
    "\n",
    "x_normal_train = ds_normal.drop('label', axis=1) .to_numpy() #ds\n",
    "x_anomaly_train = ds_anomaly.drop('label', axis=1).to_numpy() #ds\n",
    "\n",
    "print(\"ANOMALY DATASET SIZE: \", x_normal_train.shape) #dsnormal\n",
    "print(\"NORMAL  DATASET SIZE: \", x_anomaly_train.shape) #dsanomaly\n",
    "\n",
    "\n",
    "print(anomaly_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979363de",
   "metadata": {},
   "source": [
    "# Feature Selection..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "275587a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterSelection():\n",
    "    \n",
    "    def __init__(self, threshold):\n",
    "        self.col2rem = set()\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit(self, data):\n",
    "        correlation_matrix  =  np.corrcoef(data, rowvar=False)\n",
    "        for i in range(correlation_matrix.shape[0]): \n",
    "            for j in range(correlation_matrix.shape[1]): \n",
    "                if i!=j and abs(correlation_matrix[i, j]) > self.threshold:\n",
    "                     self.col2rem.add(j) \n",
    "        \n",
    "    def transform(self, data):\n",
    "        return data[:, [False if i in self.col2rem else True for i in range(data.shape[1])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87527fb4",
   "metadata": {},
   "source": [
    "# Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ce4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(data, CI):\n",
    "    print(data)\n",
    "    z_critical = stats.norm.ppf(q = CI+((1-CI)/2))\n",
    "    \n",
    "    confidence_interval_f1_score = z_critical * (data['F1_W'].std(axis=0) / math.sqrt(len(data)))\n",
    "    average_f1score = data['F1_W'].mean(axis=0) \n",
    "    \n",
    "    confidence_interval_fpr = z_critical * (data[\"FPR\"].std(axis=0) / math.sqrt(len(data)))\n",
    "    average_fpr = data[\"FPR\"].mean(axis=0)\n",
    "    \n",
    "    confidence_interval_trainingt = z_critical * (data[\"TRAINING TIME\"].std(axis=0) / math.sqrt(len(data)))\n",
    "    average_trainingt = data[\"TRAINING TIME\"].mean(axis=0)\n",
    "    \n",
    "    confidence_interval_testingt = z_critical * (data[\"TESTING TIME\"].std(axis=0) / math.sqrt(len(data)))\n",
    "    average_testingt = data[\"TESTING TIME\"].mean(axis=0)\n",
    "    \n",
    "    return average_f1score, confidence_interval_f1_score, average_fpr, confidence_interval_fpr, average_trainingt, confidence_interval_trainingt, average_testingt, confidence_interval_testingt  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c587f",
   "metadata": {},
   "source": [
    "# Nested K*I-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1697bb1d",
   "metadata": {},
   "source": [
    "Given a matrix $m \\times n$: <br>                \n",
    "$Precision_i = \\frac{M_{ii}}{\\sum_jM_{ji}}$ <br>\n",
    "$recall_i = \\frac{M_{ii}}{\\sum_jM_{ij}}$\n",
    "\n",
    "Sklearn Confusion matrix: i-th row and j-th column entry indicates the number of samples with true label being i-th class and predicted label being j-th class.: <br>\n",
    "\n",
    "   P R E D I C T E D <br>\n",
    "T <br>\n",
    "R <br>\n",
    "U <br>\n",
    "E <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99d1c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cross_val(model, params, n_folds_outer=5, n_folds_inner=5, normalization=\"standard_scaler\", apply_pca=\"no\", shuffle=True):\n",
    "   \n",
    "    \"\"\" INIT COLUMNS \"\"\"      \n",
    "    \n",
    "    # init outer_metrics_column\n",
    "    outer_col = (params_col:=list(params.keys())) + ['F1_W', 'F1_0', 'F1_1', 'RECALL_0', 'PRECISION_0', 'FPR', 'INNER_F1_W_MEAN', 'SCALER', 'PCA', 'MODEL']\n",
    "    #\n",
    "    outer_metrics_column = outer_col if model == \"ocsvm\" else  outer_col[:outer_col.index('SCALER')] + ['EPI_W'] + outer_col[outer_col.index('SCALER'):]    \n",
    "    # init inner_metrics_column\n",
    "    inner_col = ['F1_W'] if model == \"ocsvm\" else ['F1_W', 'EPI_W']\n",
    "    #\n",
    "    inner_metrics_column = params_col + inner_col\n",
    "    # init avg_inner_metrics_column\n",
    "    avg_inner_metrics_column = params_col + [c+\"_MEAN\" for c in inner_col]        \n",
    "    print(avg_inner_metrics_column) \n",
    "    \n",
    "    # save all k folds performance metrics\n",
    "    outer_metrics = pd.DataFrame(columns = outer_metrics_column)           \n",
    "   \n",
    "    \"\"\" OUTER K FOLD \"\"\"      \n",
    "    # K-Folds cross-validator  \n",
    "    kf = KFold(n_splits=n_folds_outer, shuffle=shuffle)        \n",
    "    # Generate indices to split training set data.\n",
    "    outer_normal_kf = kf.split(x_normal_train)\n",
    "    # and Generate indices to split test set data. #  into \n",
    "    outer_anomaly_kf = kf.split(x_anomaly_train)\n",
    "    \n",
    "    for outer_kf_iter, outer_normal_kf_indices in enumerate(outer_normal_kf):\n",
    "\n",
    "        \"\"\" TEST / TRAIN SPLITS \"\"\"\n",
    "\n",
    "        # get indexes for NORMAL train and test\n",
    "        outer_normal_itrain, outer_normal_itest = outer_normal_kf_indices\n",
    "        # get indexes for ANOMALY train and test\n",
    "        outer_anomaly_itrain, outer_anomaly_itest = next(outer_anomaly_kf)    \n",
    "        # get normal train dataset from indexes...\n",
    "        x_outer_normal_train = x_normal_train[outer_normal_itrain]\n",
    "        # get anomaly train dataset from indexes...\n",
    "        x_outer_anomaly_train = x_anomaly_train[outer_anomaly_itrain]\n",
    "        # get normal test dataset from indexes...\n",
    "        x_outer_normal_test = x_normal_train[outer_normal_itest]\n",
    "        # get anomaly test dataset from indexes...\n",
    "        x_outer_anomaly_test = x_anomaly_train[outer_anomaly_itest]\n",
    "        # create test set \n",
    "        x_outer_test = np.vstack((x_outer_normal_test, x_outer_anomaly_test))   \n",
    "        y_outer_test = np.concatenate((np.zeros(x_outer_normal_test.shape[0]), np.ones(x_outer_anomaly_test.shape[0])))     \n",
    "\n",
    "        \"\"\" NORMALIZATION AND PCA \"\"\"\n",
    "                                                 \n",
    "        scaler = None\n",
    "        pca = None\n",
    "\n",
    "        if normalization == \"standard_scaler\":\n",
    "            # Scale data\n",
    "            scaler = StandardScaler()\n",
    "            # Fit NORMAL train data\n",
    "            scaler = scaler.fit(x_outer_normal_train)\n",
    "            # Transform normal train data\n",
    "            x_outer_normal_train = scaler.transform(x_outer_normal_train)\n",
    "            # Transform anomaly train data\n",
    "            x_outer_anomaly_train = scaler.transform(x_outer_anomaly_train)\n",
    "            # Transform test data\n",
    "            x_outer_test = scaler.transform(x_outer_test)\n",
    "            \n",
    "        if normalization == \"min_max\":\n",
    "            # Scale data\n",
    "            scaler = MinMaxScaler()\n",
    "            # Fit NORMAL train data\n",
    "            scaler = scaler.fit(xfold_normal_train)\n",
    "            # Transform normal train data\n",
    "            xfold_normal_train = scaler.transform(xfold_normal_train)\n",
    "            # Transform anomaly train data\n",
    "            xfold_val = scaler.transform(xfold_val)\n",
    "            # Transform test data\n",
    "            xfold_test = scaler.transform(xfold_test)\n",
    "\n",
    "        if apply_pca == \"yes\":\n",
    "            # Apply PCA\n",
    "            pca = PCA(n_components = 0.99)\n",
    "            # Fit NORMAL train data\n",
    "            pca = pca.fit(x_outer_normal_train) \n",
    "            # Transform normal train data\n",
    "            x_outer_normal_train = pca.transform(x_outer_normal_train)\n",
    "            # Transform anomaly train data\n",
    "            x_outer_anomaly_train = pca.transform(x_outer_anomaly_train)\n",
    "            # Transform test data\n",
    "            x_outer_test = pca.transform(x_outer_test)\n",
    "\n",
    "        \"\"\" INNER METRICS AND INIT INNER KFOLD \"\"\"\n",
    "\n",
    "        # init inner metrics...   \n",
    "        inner_metrics = pd.DataFrame(columns = inner_metrics_column)\n",
    "\n",
    "        # Generate indices for split data into training and validation set.\n",
    "        inner_kf = KFold(n_splits=n_folds_inner, shuffle=shuffle)\n",
    "        inner_normal_kf = inner_kf.split(x_outer_normal_train)\n",
    "        inner_anomaly_kf = inner_kf.split(x_outer_anomaly_train)  \n",
    "\n",
    "        \"\"\" INNER KFOLD \"\"\"\n",
    "\n",
    "        # inner KFold...\n",
    "        for inner_kf_iter, inner_normal_kf_indices in enumerate(inner_normal_kf):\n",
    "            # get indexes for NORMAL train and validation\n",
    "            inner_normal_itrain, inner_normal_ival = inner_normal_kf_indices\n",
    "            # get indices for ANOMALY train and validation\n",
    "            _, inner_anomaly_ival = next(inner_anomaly_kf)\n",
    "            # get normal train dataset from indices... g\n",
    "            x_inner_normal_train = x_outer_normal_train[inner_normal_itrain]\n",
    "            # get normal validation dataseet from indices...\n",
    "            x_inner_normal_val = x_outer_normal_train[inner_normal_ival]\n",
    "            # get anomaly inner validation dataseet from indices...\n",
    "            x_inner_anomaly_val = x_outer_anomaly_train[inner_anomaly_ival]\n",
    "            # create validation dataset....\n",
    "            x_inner_val = np.vstack((x_inner_normal_val, x_inner_anomaly_val))\n",
    "            y_inner_val = np.concatenate((np.zeros(x_inner_normal_val.shape[0]), np.ones(x_inner_anomaly_val.shape[0])))\n",
    "\n",
    "            if model == \"kde\":\n",
    "                inner_metrics = kde_hyperparam_search(x_inner_normal_train, x_inner_val, y_inner_val, \n",
    "                                                      params, inner_metrics, inner_metrics_column)    \n",
    "            if model == \"ocsvm\":\n",
    "                inner_metrics = ocsvm_hyperparam_search(x_inner_normal_train, x_inner_val, y_inner_val,\n",
    "                                                       params, inner_metrics, inner_metrics_column)\n",
    "            if model == \"gmm\":\n",
    "                inner_metrics = gmm_hyperparam_search(x_inner_normal_train, x_inner_val, y_inner_val, \n",
    "                                                      params, inner_metrics, inner_metrics_column) \n",
    "\n",
    "        \"\"\" COMPUTE MEANS AND GET BEST HYPER-PARAMETERS \"\"\"      \n",
    "\n",
    "        # computer \n",
    "        inner_metrics = inner_metrics.set_index(params_col)   \n",
    "        #\n",
    "        avg_inner_metrics = pd.DataFrame(columns = avg_inner_metrics_column)\n",
    "        #\n",
    "        for idxs in set(inner_metrics.index.values):\n",
    "            # compute mean\n",
    "            idxs = list(idxs) if isinstance(idxs, set) else [idxs];\n",
    "            mean = inner_metrics.loc[idxs].mean(axis=0).to_numpy()\n",
    "            # append mean\n",
    "            avg_inner_metrics = avg_inner_metrics.append([pd.DataFrame([idxs+list(mean)], columns = avg_inner_metrics_column)], ignore_index=True)\n",
    "        # sort by F1_W Score\n",
    "        best_inner_f1_w_row = avg_inner_metrics.sort_values(['F1_W_MEAN']).iloc[-1]\n",
    "\n",
    "        \"\"\" RUN KDE MODEL WITH BEST HYPER-PARAMETERS \"\"\"   \n",
    "        \n",
    "        if model == \"kde\":\n",
    "            outer_metrics = kde_test_best_model(best_inner_f1_w_row, x_outer_normal_train, x_outer_test, \n",
    "                                                y_outer_test, outer_metrics, outer_metrics_column, scaler, pca)\n",
    "        \n",
    "        if model == \"ocsvm\":\n",
    "            outer_metrics = ocsvm_test_best_model(best_inner_f1_w_row, params['KERNEL'], x_outer_normal_train, x_outer_test, \n",
    "                                                y_outer_test, outer_metrics, outer_metrics_column, scaler, pca)  #  # #)\n",
    "\n",
    "        if model == \"gmm\":     \n",
    "            outer_metrics = gmm_test_best_model(best_inner_f1_w_row, x_outer_normal_train, x_outer_test, \n",
    "                                                y_outer_test, outer_metrics, outer_metrics_column, scaler, pca)\n",
    "    \"\"\" RETURN BEST MODELS\"\"\"  #DISPLAY   \n",
    "\n",
    "    \n",
    "    outer_metrics = outer_metrics.sort_values(['F1_W']) \n",
    "    return outer_metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a31c37",
   "metadata": {},
   "source": [
    "# Classic Validation-Test K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c61e6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_cross_val(model, params, n_folds=5, apply_std=True, apply_minmax=False, dim_red='pca', shuffle=True):\n",
    "   \n",
    "    \"\"\" INIT COLUMNS \"\"\"      \n",
    "    \n",
    "    # init outer_metrics_column [best_bw, f1_w, best_f1_w, f1_0, f1_1, recall_0, precision_0, FPR, best_epi, scaler, pca, kde]\n",
    "    test_col = (params_col:=list(params.keys())) + ['F1_W', 'F1_0', 'F1_1', 'RECALL_0', 'PRECISION_0', 'FPR', 'HYPER_F1_W', 'SCALER', 'PCA', 'MODEL', 'TRAINING TIME', 'TESTING TIME']\n",
    "    #\n",
    "    test_metrics_column = test_col if model == \"ocsvm\" else  test_col[:test_col.index('SCALER')] + ['EPI_W'] + test_col[test_col.index('SCALER'):]    \n",
    "    # init inner_metrics_column\n",
    "    val_col = ['F1_W'] if model == \"ocsvm\" else ['F1_W', 'EPI_W']\n",
    "    #\n",
    "    val_metrics_column = params_col + val_col          \n",
    "    \n",
    "    # save all k folds performance metrics\n",
    "    test_metrics = pd.DataFrame(columns = test_metrics_column)           \n",
    "   \n",
    "    \"\"\" OUTER K FOLD \"\"\"      \n",
    "    # K-Folds cross-validator  \n",
    "    kf = KFold(n_splits=n_folds, shuffle=shuffle)        \n",
    "    # Generate indices to split training set data.\n",
    "    normal_kf = kf.split(x_normal_train)\n",
    "    # and Generate indices to split test set data. #  into \n",
    "    anomaly_kf = kf.split(x_anomaly_train) \n",
    "    \n",
    "    for kf_iter, normal_kf_indices in enumerate(normal_kf):\n",
    "\n",
    "        \"\"\" TEST / VALIDATION / TRAIN SPLITS \"\"\"    \n",
    "\n",
    "        # get indexes for NORMAL train and test\n",
    "        normal_itrain, normal_itest = normal_kf_indices\n",
    "        # get indexes for ANOMALY train and test\n",
    "        _, anomaly_itest = next(anomaly_kf)    \n",
    "        # get normal train dataset from indexes...\n",
    "        xfold_normal_train = x_normal_train[normal_itrain]; print(\"x_normal_train shape: \", x_normal_train.shape)  \n",
    "        # get normal test dataset from indexes...\n",
    "        xfold_normal_test = x_normal_train[normal_itest]\n",
    "        # get anomaly test dataset from indexes...\n",
    "        xfold_anomaly_test = x_anomaly_train[anomaly_itest]\n",
    "        # create test set \n",
    "        xfold_test = np.vstack((xfold_normal_test, xfold_anomaly_test)); print(\"xfold_test size: \" , xfold_test.shape)     \n",
    "        yfold_test = np.concatenate((np.zeros(xfold_normal_test.shape[0]), np.ones(xfold_anomaly_test.shape[0])))\n",
    "        #print(yfold_test)\n",
    "        xfold_test, yfold_test = sklearn.utils.shuffle(xfold_test, yfold_test)\n",
    "        # divide into validation and test datasets...\n",
    "        xfold_val, xfold_test, yfold_val, yfold_test = train_test_split(xfold_test, yfold_test, test_size=0.50, stratify=yfold_test)\n",
    "        #print(\"Class 0: {} of {}. Percentage: {}\".format((yfold_val == 1).sum(), len(yfold_val), (yfold_val == 1).sum()/len(yfold_val)))\n",
    "        \n",
    "        \"\"\" NORMALIZATION AND PCA \"\"\"        \n",
    "                                                 \n",
    "        scaler = None\n",
    "        pca = None     \n",
    "\n",
    "        if  apply_std:\n",
    "            # Scale data\n",
    "            scaler = StandardScaler()\n",
    "            # Fit NORMAL train data\n",
    "            scaler = scaler.fit(xfold_normal_train)\n",
    "            # Transform normal train data\n",
    "            xfold_normal_train = scaler.transform(xfold_normal_train)\n",
    "            # Transform anomaly train data\n",
    "            xfold_val = scaler.transform(xfold_val) \n",
    "            # Transform test data\n",
    "            xfold_test = scaler.transform(xfold_test) \n",
    "            \n",
    "        if apply_minmax:\n",
    "            # Scale data\n",
    "            scaler = MinMaxScaler()\n",
    "            # Fit NORMAL train data\n",
    "            scaler = scaler.fit(xfold_normal_train)\n",
    "            # Transform normal train data\n",
    "            xfold_normal_train = scaler.transform(xfold_normal_train)\n",
    "            # Transform anomaly train data\n",
    "            xfold_val = scaler.transform(xfold_val)\n",
    "            # Transform test data\n",
    "            xfold_test = scaler.transform(xfold_test)\n",
    "            \n",
    "        if dim_red == \"pca\":\n",
    "            # Apply PCA\n",
    "            pca = PCA(n_components = 0.99) #975908585\n",
    "            # Fit NORMAL train data\n",
    "            pca = pca.fit(xfold_normal_train) \n",
    "            # Transform normal train data\n",
    "            xfold_normal_train = pca.transform(xfold_normal_train)\n",
    "            # Transform anomaly train data\n",
    "            xfold_val = pca.transform(xfold_val)\n",
    "            # Transform test data\n",
    "            xfold_test = pca.transform(xfold_test) #_outer_outer___outer_outer__ _outer_outer__  INNER METRICS\n",
    "        \n",
    "        if dim_red == \"fs\":\n",
    "            # apply filter selecdtion else else else else elseelseelse elseelse else elseelse elseelseelse\n",
    "            fs = FilterSelection(0.95) ##7808509\n",
    "            # fit NORMAL train data\n",
    "            fs.fit(xfold_normal_train)\n",
    "            # Transform normal train data\n",
    "            xfold_normal_train = fs.transform(xfold_normal_train)\n",
    "            # Transform anomaly train data\n",
    "            xfold_val = fs.transform(xfold_val)\n",
    "            # Transform test data\n",
    "            xfold_test = fs.transform(xfold_test)   \n",
    "            print(xfold_val.shape)\n",
    "            \n",
    "        \"\"\" HYPER-PARAMETER TUNNING \"\"\"\n",
    "\n",
    "        # init inner metrics...   \n",
    "        val_metrics = pd.DataFrame(columns = val_metrics_column)\n",
    "        start_time = None\n",
    "            # start recoding time \n",
    "        end_time = None\n",
    "        \n",
    "        if model == \"kde\":\n",
    "            start_time = time.time()\n",
    "            val_metrics = kde_hyperparam_search(xfold_normal_train, xfold_val, yfold_val, \n",
    "                                                params, val_metrics, val_metrics_column)   \n",
    "            end_time = time.time() - start_time\n",
    "        if model == \"ocsvm\":\n",
    "            start_time = time.time()\n",
    "            val_metrics = ocsvm_hyperparam_search(xfold_normal_train, xfold_val, yfold_val,\n",
    "                                                params, val_metrics, val_metrics_column)\n",
    "            end_time = time.time() - start_time\n",
    "        if model == \"gmm\":\n",
    "            start_time = time.time()\n",
    "            val_metrics = gmm_hyperparam_search(xfold_normal_train, xfold_val, yfold_val, \n",
    "                                                params, val_metrics, val_metrics_column) #   innerinner_inner_inner   innerinner_inner_inner    innerinner_inner_inner \n",
    "            end_time = time.time() - start_time\n",
    "        if model == \"lof\":\n",
    "            start_time = time.time()\n",
    "            val_metrics = lof_hyperparam_search(xfold_normal_train, xfold_val, yfold_val,\n",
    "                                                params, val_metrics, val_metrics_column)\n",
    "            end_time = time.time() - start_time\n",
    "        #   innerinner_inner_inner \n",
    "        \"\"\" COMPUTE MEANS AND GET BEST HYPER-PARAMETERS \"\"\"      \n",
    "\n",
    "        # sort by F1_W Score\n",
    "        best_val_f1_w_row = val_metrics.sort_values(['F1_W']).iloc[-1]\n",
    "        end_time = 1913/end_time #\n",
    "\n",
    "        \"\"\" RUN KDE MODEL WITH BEST HYPER-PARAMETERS \"\"\"   \n",
    "        \n",
    "        if model == \"kde\":\n",
    "            test_metrics = kde_test_best_model('classic', best_val_f1_w_row, xfold_normal_train, xfold_test, \n",
    "                                                yfold_test, test_metrics, test_metrics_column, scaler, pca, end_time)\n",
    "        \n",
    "        if model == \"ocsvm\":\n",
    "            test_metrics = ocsvm_test_best_model('classic', best_val_f1_w_row, params['KERNEL'], xfold_normal_train, xfold_test, \n",
    "                                                yfold_test, test_metrics, test_metrics_column, scaler, pca, end_time)  #  # #)\n",
    "\n",
    "        if model == \"gmm\":     \n",
    "            test_metrics = gmm_test_best_model('classic', best_val_f1_w_row, xfold_normal_train, xfold_test, \n",
    "                                                yfold_test, test_metrics, test_metrics_column, scaler, pca, end_time)\n",
    "        \n",
    "        if model == \"lof\":\n",
    "            test_metrics = lof_test_best_model('classic', best_val_f1_w_row, xfold_normal_train, xfold_test, \n",
    "                                                yfold_test, test_metrics, test_metrics_column, scaler, pca, end_time)\n",
    "    \"\"\" RETURN BEST MODELS\"\"\"  #DISPLAY   \n",
    "    \n",
    "    test_metrics = test_metrics.sort_values(['F1_W']) \n",
    "    return test_metrics       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f3922",
   "metadata": {},
   "source": [
    "# Mixture of Gaussians (GMM) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac556c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d8df0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_RESOLUTION = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e55b6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_hyperparam_search(xnormal_train, xval, yval, params, metrics, metrics_column):\n",
    "    # search for the best 'n_components' hyper-parameter\n",
    "    for ncomp in params['N_COMPONENTS']:\n",
    "        # fit normal data in model\n",
    "        g = GaussianMixture(n_components=ncomp).fit(xnormal_train)\n",
    "        # cross-validation\n",
    "        scores = g.score_samples(xval)\n",
    "        # fetch performance metrics from KDE threshold\n",
    "        f1_w, epi_w = val_threshold(scores, yval, step_resolution=STEP_RESOLUTION)\n",
    "        # save metrics bw\n",
    "        metrics = metrics.append(pd.DataFrame([[ncomp, f1_w, epi_w]], columns=metrics_column), ignore_index=True)\n",
    "        #\n",
    "        print(\"ncom = {}, f1_w score = {}\".format(ncomp, f1_w))\n",
    "        \n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cae0d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_test_best_model(cv_type, best_row, xnormal_train, xtest, ytest, metrics, metrics_column, scaler, pca, testing_time):\n",
    "    #\n",
    "    if cv_type == \"classic\":\n",
    "        best_ncomp, best_f1, best_epi = best_row['N_COMPONENTS'],  best_row['F1_W'], best_row['EPI_W'] \n",
    "    else:\n",
    "        best_ncomp, best_f1, best_epi = best_row['N_COMPONENTS'],  best_row['F1_W_MEAN'], best_row['EPI_W_MEAN'] \n",
    "\n",
    "    # start recoding time \n",
    "    start_time = time.time()\n",
    "    # fit normal data in model\n",
    "    g = GaussianMixture(n_components=best_ncomp).fit(xnormal_train)\n",
    "    # cross-validation\n",
    "    scores = g.score_samples(xtest)\n",
    "    # fetch performance metrics from KDE threshold++\n",
    "    f1_0, f1_1, f1_w, recall_0, precision_0, FPR, precision_w, recall_w\\\n",
    "        = test_threshold(scores, ytest, best_epi)\n",
    "    # finish recording time\n",
    "    end_time = 254/(time.time() - start_time)\n",
    "    #\n",
    "    metrics = metrics.append(pd.DataFrame([[best_ncomp, f1_w, f1_0, f1_1, recall_0, precision_0, FPR, best_f1, best_epi, scaler, pca, g, testing_time, end_time]], columns=metrics_column), ignore_index=True)\n",
    "    print(\"best outer ncomponents = {}, best outer f1_w score = {}\\n\".format(best_ncomp, f1_w)) \n",
    "    #\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57010cee",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "035f9da1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3228, 150)\n",
      "[[807   0]\n",
      " [416 391]]\n",
      "ncom = 5, f1_w score = 0.7239142413052952\n",
      "[[807   0]\n",
      " [491 316]]\n",
      "ncom = 10, f1_w score = 0.6647620578574103\n",
      "[[807   0]\n",
      " [355 452]]\n",
      "ncom = 15, f1_w score = 0.7688678084576221\n",
      "[[807   0]\n",
      " [385 422]]\n",
      "ncom = 20, f1_w score = 0.747070443276968\n",
      "[[807   0]\n",
      " [377 430]]\n",
      "ncom = 25, f1_w score = 0.7529391558699678\n",
      "[[807   0]\n",
      " [334 473]]\n",
      "ncom = 30, f1_w score = 0.783802297227926\n",
      "[[807   0]\n",
      " [326 481]]\n",
      "ncom = 35, f1_w score = 0.789426586412243\n",
      "[[807   0]\n",
      " [358 449]]\n",
      "ncom = 40, f1_w score = 0.7667132853580703\n",
      "[[807   0]\n",
      " [302 505]]\n",
      "ncom = 45, f1_w score = 0.8060985157085392\n",
      "[[807   0]\n",
      " [346 461]]\n",
      "ncom = 50, f1_w score = 0.7752993626472672\n",
      "\n",
      "best outer ncomponents = 45, best outer f1_w score = 0.7908272733818129\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[807   0]\n",
      " [531 275]]\n",
      "ncom = 5, f1_w score = 0.6306178557797428\n",
      "[[807   0]\n",
      " [506 300]]\n",
      "ncom = 10, f1_w score = 0.6519081169606605\n",
      "[[807   0]\n",
      " [473 333]]\n",
      "ncom = 15, f1_w score = 0.6790411649859724\n",
      "[[807   0]\n",
      " [364 442]]\n",
      "ncom = 20, f1_w score = 0.7621545331985169\n",
      "[[807   0]\n",
      " [424 382]]\n",
      "ncom = 25, f1_w score = 0.7175252690463682\n",
      "[[807   0]\n",
      " [416 390]]\n",
      "ncom = 30, f1_w score = 0.723623902334547\n",
      "[[807   0]\n",
      " [408 398]]\n",
      "ncom = 35, f1_w score = 0.7296745763380226\n",
      "[[807   0]\n",
      " [361 445]]\n",
      "ncom = 40, f1_w score = 0.7643230225945825\n",
      "[[807   0]\n",
      " [353 453]]\n",
      "ncom = 45, f1_w score = 0.7700788183745058\n",
      "[[807   0]\n",
      " [381 425]]\n",
      "ncom = 50, f1_w score = 0.7497590442393555\n",
      "\n",
      "best outer ncomponents = 45, best outer f1_w score = 0.771769666601496\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[806   0]\n",
      " [696 111]]\n",
      "ncom = 5, f1_w score = 0.47013513666587375\n",
      "[[806   0]\n",
      " [277 530]]\n",
      "ncom = 10, f1_w score = 0.8230906563329878\n",
      "[[806   0]\n",
      " [389 418]]\n",
      "ncom = 15, f1_w score = 0.7440230904955686\n",
      "[[806   0]\n",
      " [396 411]]\n",
      "ncom = 20, f1_w score = 0.7388328459560771\n",
      "[[806   0]\n",
      " [419 388]]\n",
      "ncom = 25, f1_w score = 0.7215350354031342\n",
      "[[806   0]\n",
      " [463 344]]\n",
      "ncom = 30, f1_w score = 0.6873042822898894\n",
      "[[806   0]\n",
      " [368 439]]\n",
      "ncom = 35, f1_w score = 0.7593981549037729\n",
      "[[806   0]\n",
      " [363 444]]\n",
      "ncom = 40, f1_w score = 0.7630173329690677\n",
      "[[806   0]\n",
      " [356 451]]\n",
      "ncom = 45, f1_w score = 0.7680584099163725\n",
      "[[806   0]\n",
      " [415 392]]\n",
      "ncom = 50, f1_w score = 0.7245710843561872\n",
      "\n",
      "best outer ncomponents = 10, best outer f1_w score = 0.7715117651688046\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[807   0]\n",
      " [445 361]]\n",
      "ncom = 5, f1_w score = 0.7012780224175178\n",
      "[[807   0]\n",
      " [520 286]]\n",
      "ncom = 10, f1_w score = 0.6400678359441245\n",
      "[[807   0]\n",
      " [428 378]]\n",
      "ncom = 15, f1_w score = 0.7144575403023004\n",
      "[[807   0]\n",
      " [453 353]]\n",
      "ncom = 20, f1_w score = 0.6949938075338957\n",
      "[[807   0]\n",
      " [408 398]]\n",
      "ncom = 25, f1_w score = 0.7296745763380226\n",
      "[[807   0]\n",
      " [289 517]]\n",
      "ncom = 30, f1_w score = 0.8148457958532277\n",
      "[[807   0]\n",
      " [384 422]]\n",
      "ncom = 35, f1_w score = 0.7475521123729593\n",
      "[[807   0]\n",
      " [341 465]]\n",
      "ncom = 40, f1_w score = 0.7786413823217516\n",
      "[[807   0]\n",
      " [369 437]]\n",
      "ncom = 45, f1_w score = 0.7585279379958935\n",
      "[[807   0]\n",
      " [384 422]]\n",
      "ncom = 50, f1_w score = 0.7475521123729593\n",
      "\n",
      "best outer ncomponents = 30, best outer f1_w score = 0.7593981549037729\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[806   0]\n",
      " [442 365]]\n",
      "ncom = 5, f1_w score = 0.7038385103901152\n",
      "[[806   0]\n",
      " [303 504]]\n",
      "ncom = 10, f1_w score = 0.8053270877272645\n",
      "[[806   0]\n",
      " [431 376]]\n",
      "ncom = 15, f1_w score = 0.7123538760272071\n",
      "[[806   0]\n",
      " [443 364]]\n",
      "ncom = 20, f1_w score = 0.7030595431774784\n",
      "[[806   0]\n",
      " [348 459]]\n",
      "ncom = 25, f1_w score = 0.7737837315020796\n",
      "[[806   0]\n",
      " [368 439]]\n",
      "ncom = 30, f1_w score = 0.7593981549037729\n",
      "[[806   0]\n",
      " [410 397]]\n",
      "ncom = 35, f1_w score = 0.7283494517122285\n",
      "[[806   0]\n",
      " [354 453]]\n",
      "ncom = 40, f1_w score = 0.7694932907038705\n",
      "[[806   0]\n",
      " [435 372]]\n",
      "ncom = 45, f1_w score = 0.7092685752500711\n",
      "[[806   0]\n",
      " [381 426]]\n",
      "ncom = 50, f1_w score = 0.7499142375443004\n",
      "\n",
      "best outer ncomponents = 10, best outer f1_w score = 0.7657656090663705\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[807   0]\n",
      " [427 379]]\n",
      "ncom = 5, f1_w score = 0.7152256381313867\n",
      "[[807   0]\n",
      " [603 203]]\n",
      "ncom = 10, f1_w score = 0.5651947090528947\n",
      "[[807   0]\n",
      " [486 320]]\n",
      "ncom = 15, f1_w score = 0.6684775437706165\n",
      "[[807   0]\n",
      " [336 470]]\n",
      "ncom = 20, f1_w score = 0.7821847118398843\n",
      "[[807   0]\n",
      " [343 463]]\n",
      "ncom = 25, f1_w score = 0.7772200820396604\n",
      "[[807   0]\n",
      " [376 430]]\n",
      "ncom = 30, f1_w score = 0.7534240783204047\n",
      "[[807   0]\n",
      " [365 441]]\n",
      "ncom = 35, f1_w score = 0.7614304649501401\n",
      "[[807   0]\n",
      " [341 465]]\n",
      "ncom = 40, f1_w score = 0.7786413823217516\n",
      "[[807   0]\n",
      " [287 519]]\n",
      "ncom = 45, f1_w score = 0.8162115272001826\n",
      "[[807   0]\n",
      " [337 469]]\n",
      "ncom = 50, f1_w score = 0.7814771710837077\n",
      "\n",
      "best outer ncomponents = 45, best outer f1_w score = 0.7739098352468076\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[807   0]\n",
      " [440 366]]\n",
      "ncom = 5, f1_w score = 0.7051786076281692\n",
      "[[807   0]\n",
      " [566 240]]\n",
      "ncom = 10, f1_w score = 0.5996289929306927\n",
      "[[807   0]\n",
      " [428 378]]\n",
      "ncom = 15, f1_w score = 0.7144575403023004\n",
      "[[807   0]\n",
      " [397 409]]\n",
      "ncom = 20, f1_w score = 0.7379184035131878\n",
      "[[807   0]\n",
      " [365 441]]\n",
      "ncom = 25, f1_w score = 0.7614304649501401\n",
      "[[807   0]\n",
      " [356 450]]\n",
      "ncom = 30, f1_w score = 0.7679249248278315\n",
      "[[807   0]\n",
      " [407 399]]\n",
      "ncom = 35, f1_w score = 0.7304276055771248\n",
      "[[807   0]\n",
      " [325 481]]\n",
      "ncom = 40, f1_w score = 0.7899312881262339\n",
      "[[807   0]\n",
      " [350 456]]\n",
      "ncom = 45, f1_w score = 0.7722273506314936\n",
      "[[807   0]\n",
      " [382 424]]\n",
      "ncom = 50, f1_w score = 0.7490240643889404\n",
      "\n",
      "best outer ncomponents = 40, best outer f1_w score = 0.7709257926351022\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[806   0]\n",
      " [421 386]]\n",
      "ncom = 5, f1_w score = 0.7200125011905405\n",
      "[[806   0]\n",
      " [488 319]]\n",
      "ncom = 10, f1_w score = 0.6671132538272858\n",
      "[[806   0]\n",
      " [465 342]]\n",
      "ncom = 15, f1_w score = 0.6857098320408401\n",
      "[[806   0]\n",
      " [419 388]]\n",
      "ncom = 20, f1_w score = 0.7215350354031342\n",
      "[[806   0]\n",
      " [326 481]]\n",
      "ncom = 25, f1_w score = 0.7893398778275612\n",
      "[[806   0]\n",
      " [388 419]]\n",
      "ncom = 30, f1_w score = 0.7447618270799348\n",
      "[[806   0]\n",
      " [355 452]]\n",
      "ncom = 35, f1_w score = 0.7687761487902254\n",
      "[[806   0]\n",
      " [321 486]]\n",
      "ncom = 40, f1_w score = 0.79283851244054\n",
      "[[806   0]\n",
      " [331 476]]\n",
      "ncom = 45, f1_w score = 0.785827895489093\n",
      "[[806   0]\n",
      " [426 381]]\n",
      "ncom = 50, f1_w score = 0.7161928410701719\n",
      "\n",
      "best outer ncomponents = 40, best outer f1_w score = 0.7636008097165992\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[806   0]\n",
      " [486 321]]\n",
      "ncom = 5, f1_w score = 0.668749873232866\n",
      "[[806   0]\n",
      " [511 296]]\n",
      "ncom = 10, f1_w score = 0.6480104574984766\n",
      "[[806   0]\n",
      " [357 450]]\n",
      "ncom = 15, f1_w score = 0.7673400718293453\n",
      "[[806   0]\n",
      " [354 453]]\n",
      "ncom = 20, f1_w score = 0.7694932907038705\n",
      "[[806   0]\n",
      " [355 452]]\n",
      "ncom = 25, f1_w score = 0.7687761487902254\n",
      "[[806   0]\n",
      " [349 458]]\n",
      "ncom = 30, f1_w score = 0.7730701243416584\n",
      "[[806   0]\n",
      " [349 458]]\n",
      "ncom = 35, f1_w score = 0.7730701243416584\n",
      "[[806   0]\n",
      " [394 413]]\n",
      "ncom = 40, f1_w score = 0.7403192063154798\n",
      "[[806   0]\n",
      " [364 443]]\n",
      "ncom = 45, f1_w score = 0.7622947368421052\n",
      "[[806   0]\n",
      " [342 465]]\n",
      "ncom = 50, f1_w score = 0.7780532434676812\n",
      "\n",
      "best outer ncomponents = 50, best outer f1_w score = 0.7657656090663705\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[807   0]\n",
      " [531 275]]\n",
      "ncom = 5, f1_w score = 0.6306178557797428\n",
      "[[807   0]\n",
      " [577 229]]\n",
      "ncom = 10, f1_w score = 0.5895810044163983\n",
      "[[807   0]\n",
      " [432 374]]\n",
      "ncom = 15, f1_w score = 0.7113773050350416\n",
      "[[807   0]\n",
      " [392 414]]\n",
      "ncom = 20, f1_w score = 0.7416373829331677\n",
      "[[807   0]\n",
      " [416 390]]\n",
      "ncom = 25, f1_w score = 0.723623902334547\n",
      "[[807   0]\n",
      " [442 364]]\n",
      "ncom = 30, f1_w score = 0.7036208387375702\n",
      "[[806   1]\n",
      " [359 447]]\n",
      "ncom = 35, f1_w score = 0.7651814396770091\n",
      "[[807   0]\n",
      " [352 454]]\n",
      "ncom = 40, f1_w score = 0.7707955884965041\n",
      "[[807   0]\n",
      " [361 445]]\n",
      "ncom = 45, f1_w score = 0.7643230225945825\n",
      "[[807   0]\n",
      " [381 425]]\n",
      "ncom = 50, f1_w score = 0.7497590442393555\n",
      "\n",
      "best outer ncomponents = 40, best outer f1_w score = 0.7506476473153554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gmm_params = {\n",
    "    'N_COMPONENTS' : [5, 10, 15, 20, 25, 30, 35, 40, 45,50  ] \n",
    "}   \n",
    "\n",
    "test_metrics = classic_cross_val(model=\"gmm\", params=gmm_params, apply_std=True, apply_minmax=False, \n",
    "                                  dim_red=\"pca\",n_folds=10) \n",
    "\n",
    "\n",
    "#test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca9f16a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N_COMPONENTS      F1_W      F1_0      F1_1  RECALL_0  PRECISION_0       FPR  \\\n",
      "9           40  0.750648  0.809237  0.692058  1.000000     0.679595  0.320405   \n",
      "3           30  0.759398  0.814141  0.704655  1.000000     0.686542  0.313458   \n",
      "7           40  0.763601  0.816802  0.710400  1.000000     0.690334  0.309666   \n",
      "4           10  0.765766  0.818044  0.713488  1.000000     0.692110  0.307890   \n",
      "8           50  0.765766  0.818044  0.713488  1.000000     0.692110  0.307890   \n",
      "6           40  0.770926  0.820774  0.721078  1.000000     0.696028  0.303972   \n",
      "2           10  0.771512  0.821374  0.721649  1.000000     0.696891  0.303109   \n",
      "1           45  0.771770  0.821010  0.722530  0.998759     0.696970  0.303030   \n",
      "5           45  0.773910  0.822268  0.725552  0.998759     0.698785  0.301215   \n",
      "0           45  0.790827  0.832817  0.748837  1.000000     0.713528  0.286472   \n",
      "\n",
      "   HYPER_F1_W         EPI_W            SCALER                     PCA  \\\n",
      "9    0.770796 -13175.177420  StandardScaler()  PCA(n_components=0.99)   \n",
      "3    0.814846  -4946.436336  StandardScaler()  PCA(n_components=0.99)   \n",
      "7    0.792839 -12820.019185  StandardScaler()  PCA(n_components=0.99)   \n",
      "4    0.805327   -549.811013  StandardScaler()  PCA(n_components=0.99)   \n",
      "8    0.778053 -18398.145753  StandardScaler()  PCA(n_components=0.99)   \n",
      "6    0.789931  -9890.848690  StandardScaler()  PCA(n_components=0.99)   \n",
      "2    0.823091   -562.383467  StandardScaler()  PCA(n_components=0.99)   \n",
      "1    0.770079 -14080.975481  StandardScaler()  PCA(n_components=0.99)   \n",
      "5    0.816212 -12988.348476  StandardScaler()  PCA(n_components=0.99)   \n",
      "0    0.806099  -9369.402996  StandardScaler()  PCA(n_components=0.99)   \n",
      "\n",
      "                              MODEL  TRAINING TIME  TESTING TIME  \n",
      "9  GaussianMixture(n_components=40)      25.641584     48.036617  \n",
      "3  GaussianMixture(n_components=30)      23.783959     63.772740  \n",
      "7  GaussianMixture(n_components=40)      32.652402     62.437874  \n",
      "4  GaussianMixture(n_components=10)      28.861278    131.094516  \n",
      "8  GaussianMixture(n_components=50)      31.845213     55.554367  \n",
      "6  GaussianMixture(n_components=40)      32.471847     70.459724  \n",
      "2  GaussianMixture(n_components=10)      28.018438    167.570152  \n",
      "1  GaussianMixture(n_components=45)      25.415258     29.413003  \n",
      "5  GaussianMixture(n_components=45)      25.993616     39.564148  \n",
      "0  GaussianMixture(n_components=45)      28.634959     34.651250  \n",
      "Average F1 Score: 0.7684122163102491 +/- 0.00651308692325521\n",
      "Average FPR: 0.3057108715384407 +/- 0.005498753431374768\n",
      "Average Training Time: 28.331855252602956 +/- 1.9655696449169786\n",
      "Average Testing Time\": 70.25543924047412 +/- 27.61180787202155\n"
     ]
    }
   ],
   "source": [
    "average_f1score, confidence_int_f1_score, average_fpr, confidence_int_fpr, average_training_time, confidence_int_training_time, average_testing_time, confidence_int_testing_time = confidence_interval(test_metrics, 0.95)\n",
    "print(f'Average F1 Score: {average_f1score} +/- {confidence_int_f1_score}')\n",
    "print(f'Average FPR: {average_fpr} +/- {confidence_int_fpr}')\n",
    "print(f'Average Training Time: {average_training_time} +/- {confidence_int_training_time}')\n",
    "print(f'Average Testing Time\": {average_testing_time} +/- {confidence_int_testing_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ce55a",
   "metadata": {},
   "source": [
    "#### Test on new and unseen data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44fd4ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Score Weighted in Test Set:  0.9998403575949097\n",
      "False Positive Rate in Test set:  0.0\n"
     ]
    }
   ],
   "source": [
    "best_bw = test_metrics.iloc[-1]['N_COMPONENTS']\n",
    "best_epi = test_metrics.iloc[-1]['EPI_W']\n",
    "best_scaler = test_metrics.iloc[-1]['SCALER']\n",
    "best_pca = test_metrics.iloc[-1]['PCA']\n",
    "best_model = test_metrics.iloc[-1]['MODEL']\n",
    "#outer_metrics.iloc[-1]\n",
    "\n",
    "#scale data\n",
    "x_test_scaled = best_scaler.transform(x_test)\n",
    "\n",
    "#print(y_test)\n",
    "\n",
    "# apply pca to dataz\n",
    "x_test_pca = best_pca.transform(x_test_scaled)  \n",
    "#x_test_pca = x_test_scaled #:q \n",
    "\n",
    "# test best model with best parameters\n",
    "scores = best_model.score_samples(x_test_pca)         \n",
    "\n",
    "# test model with unseen data\n",
    "f1_0, f1_1, f1_w, recall_0, precision_0, FPR2, precision_w, recall_w = test_threshold(scores, y_test, best_epi)  # ?T?T ?T\n",
    "\n",
    "print(\"F1 Score Weighted in Test Set: \", f1_w)    \n",
    "print(\"False Positive Rate in Test set: \", FPR2)\n",
    "\n",
    "#allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cddb90",
   "metadata": {},
   "source": [
    "# Kernel Density Estimation (KDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c5980bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca8341",
   "metadata": {},
   "source": [
    "### Parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a2eca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE, threshold and CV parameters #\n",
    "BANDWIDTH = [0.1, 0.2, 0.5]  \n",
    "STEP_RESOLUTION = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288247ce",
   "metadata": {},
   "source": [
    "### Hyper-parameter optimization and model testing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74790593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_hyperparam_search(xnormal_train, xval, yval, params, metrics, metrics_column):\n",
    "    # search for best 'bw' hyper-parameter\n",
    "    for bw in params['BANDWIDTH']:   \n",
    "        #fit KDE\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=bw).fit(xnormal_train)       \n",
    "        # cross-validation\n",
    "        scores = kde.score_samples(xval)\n",
    "        # fetch performance metrics from KDE threshold\n",
    "        f1_w, epi_w = val_threshold(scores, yval, step_resolution=STEP_RESOLUTION)\n",
    "        # save metricsvalwstep_resolution=STEP_RESOLUTIONwstep_resolution=STEP_RESOLUTION\n",
    "        metrics = metrics.append(pd.DataFrame([[bw, f1_w, epi_w]], columns=metrics_column), ignore_index=True)  \n",
    "        #f1_w, f1_w, \n",
    "        print(\"bw = {}, f1_w score = {}\".format( bw, f1_w))\n",
    "    #\n",
    "    return metrics           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a710592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_test_best_model(cv_type, best_row, xnormal_train, xtest, ytest, metrics, metrics_column, scaler, pca, testing_time):\n",
    "    if cv_type == \"classic\":\n",
    "        best_bw, best_f1_w, best_epi = best_row['BANDWIDTH'], best_row['F1_W'], best_row['EPI_W']     \n",
    "    else:\n",
    "        best_bw, best_f1_w, best_epi = best_row['BANDWIDTH'], best_row['F1_W_MEAN'], best_row['EPI_W_MEAN']     \n",
    "\n",
    "    # start recoding time \n",
    "    start_time = time.time()\n",
    "    # run model with best parameters to date...a\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=best_bw).fit(xnormal_train)\n",
    "    # test \n",
    "    scores = kde.score_samples(xtest)\n",
    "    # fetch performance metrics from threshold...\n",
    "    f1_0, f1_1, f1_w, recall_0, precision_0, FPR, precision_w, recall_w\\\n",
    "        = test_threshold(scores, ytest, best_epi)\n",
    "    # finish recording time\n",
    "    end_time = 254/(time.time() - start_time)\n",
    "    #  \n",
    "    metrics = metrics.append(pd.DataFrame([[best_bw, f1_w, f1_0, f1_1, recall_0, precision_0, FPR, best_f1_w, best_epi, scaler, pca, kde, testing_time, end_time]], columns=metrics_column), ignore_index=True)\n",
    "    print(\"best outer bw = {}, best outer f1_w score = {}\\n\".format(best_bw, f1_w))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b65dfb",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b838b8c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3228, 150)\n",
      "[[807   0]\n",
      " [270 537]]\n",
      "bw = 0.001, f1_w score = 0.8278975204731575\n",
      "[[807   0]\n",
      " [270 537]]\n",
      "bw = 0.005, f1_w score = 0.8278975204731575\n",
      "[[807   0]\n",
      " [270 537]]\n",
      "bw = 0.01, f1_w score = 0.8278975204731575\n",
      "[[807   0]\n",
      " [274 533]]\n",
      "bw = 0.05, f1_w score = 0.8251976347078169\n",
      "[[807   0]\n",
      " [289 518]]\n",
      "bw = 0.1, f1_w score = 0.8150106584439663\n",
      "[[801   6]\n",
      " [251 556]]\n",
      "bw = 1, f1_w score = 0.8370126810875251\n",
      "[[738  69]\n",
      " [338 469]]\n",
      "bw = 3, f1_w score = 0.7406266595857673\n",
      "[[674 133]\n",
      " [370 437]]\n",
      "bw = 5, f1_w score = 0.6814840709079117\n",
      "[[638 169]\n",
      " [367 440]]\n",
      "bw = 7, f1_w score = 0.6628315935196618\n",
      "[[674 133]\n",
      " [405 402]]\n",
      "bw = 10, f1_w score = 0.656923001550368\n",
      "\n",
      "best outer bw = 1.0, best outer f1_w score = 0.8711438471157789\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[807   0]\n",
      " [246 560]]\n",
      "bw = 0.001, f1_w score = 0.8438270438766353\n",
      "[[807   0]\n",
      " [246 560]]\n",
      "bw = 0.005, f1_w score = 0.8438270438766353\n",
      "[[807   0]\n",
      " [246 560]]\n",
      "bw = 0.01, f1_w score = 0.8438270438766353\n",
      "[[807   0]\n",
      " [253 553]]\n",
      "bw = 0.05, f1_w score = 0.839161092725085\n",
      "[[807   0]\n",
      " [269 537]]\n",
      "bw = 0.1, f1_w score = 0.8284225082438038\n",
      "[[801   6]\n",
      " [237 569]]\n",
      "bw = 1, f1_w score = 0.84616661662634\n",
      "[[778  29]\n",
      " [343 463]]\n",
      "bw = 3, f1_w score = 0.7602295903688407\n",
      "[[679 128]\n",
      " [333 473]]\n",
      "bw = 5, f1_w score = 0.7094582846390056\n",
      "[[671 136]\n",
      " [350 456]]\n",
      "bw = 7, f1_w score = 0.6932480912087603\n",
      "[[673 134]\n",
      " [365 441]]\n",
      "bw = 10, f1_w score = 0.6841034637717847\n",
      "\n",
      "best outer bw = 1.0, best outer f1_w score = 0.8493592862681328\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[806   0]\n",
      " [246 561]]\n",
      "bw = 0.001, f1_w score = 0.8438875040129927\n",
      "[[806   0]\n",
      " [246 561]]\n",
      "bw = 0.005, f1_w score = 0.8438875040129927\n",
      "[[806   0]\n",
      " [246 561]]\n",
      "bw = 0.01, f1_w score = 0.8438875040129927\n",
      "[[806   0]\n",
      " [253 554]]\n",
      "bw = 0.05, f1_w score = 0.8392252188010314\n",
      "[[806   0]\n",
      " [259 548]]\n",
      "bw = 0.1, f1_w score = 0.8352137203894754\n",
      "[[802   4]\n",
      " [236 571]]\n",
      "bw = 1, f1_w score = 0.848093397917445\n",
      "[[750  56]\n",
      " [324 483]]\n",
      "bw = 3, f1_w score = 0.7577771806139546\n",
      "[[673 133]\n",
      " [348 459]]\n",
      "bw = 5, f1_w score = 0.6964549312531861\n",
      "[[705 101]\n",
      " [396 411]]\n",
      "bw = 7, f1_w score = 0.6812903102690578\n",
      "[[675 131]\n",
      " [372 435]]\n",
      "bw = 10, f1_w score = 0.6810986219861968\n",
      "\n",
      "best outer bw = 1.0, best outer f1_w score = 0.8636658183150046\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[805   1]\n",
      " [256 551]]\n",
      "bw = 0.001, f1_w score = 0.8366181851001852\n",
      "[[805   1]\n",
      " [256 551]]\n",
      "bw = 0.005, f1_w score = 0.8366181851001852\n",
      "[[805   1]\n",
      " [256 551]]\n",
      "bw = 0.01, f1_w score = 0.8366181851001852\n",
      "[[805   1]\n",
      " [261 546]]\n",
      "bw = 0.05, f1_w score = 0.8332709982451489\n",
      "[[805   1]\n",
      " [280 527]]\n",
      "bw = 0.1, f1_w score = 0.8204572417740648\n",
      "[[792  14]\n",
      " [233 574]]\n",
      "bw = 1, f1_w score = 0.8440200528923418\n",
      "[[744  62]\n",
      " [328 479]]\n",
      "bw = 3, f1_w score = 0.7515073804761047\n",
      "[[685 121]\n",
      " [356 451]]\n",
      "bw = 5, f1_w score = 0.697920269743421\n",
      "[[638 168]\n",
      " [329 478]]\n",
      "bw = 7, f1_w score = 0.6888166110220253\n",
      "[[685 121]\n",
      " [386 421]]\n",
      "bw = 10, f1_w score = 0.6770270841322505\n",
      "\n",
      "best outer bw = 1.0, best outer f1_w score = 0.8544140211531677\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[807   0]\n",
      " [232 574]]\n",
      "bw = 0.001, f1_w score = 0.8531034591046839\n",
      "[[807   0]\n",
      " [232 574]]\n",
      "bw = 0.005, f1_w score = 0.8531034591046839\n",
      "[[807   0]\n",
      " [232 574]]\n",
      "bw = 0.01, f1_w score = 0.8531034591046839\n",
      "[[807   0]\n",
      " [240 566]]\n",
      "bw = 0.05, f1_w score = 0.847811524054837\n",
      "[[807   0]\n",
      " [260 546]]\n",
      "bw = 0.1, f1_w score = 0.8344758230030376\n",
      "[[802   5]\n",
      " [212 594]]\n",
      "bw = 1, f1_w score = 0.8631931538144346\n",
      "[[725  82]\n",
      " [289 517]]\n",
      "bw = 3, f1_w score = 0.7661044242633882\n",
      "[[672 135]\n",
      " [326 480]]\n",
      "bw = 5, f1_w score = 0.710089457504274\n",
      "[[683 124]\n",
      " [351 455]]\n",
      "bw = 7, f1_w score = 0.6995138805820884\n",
      "[[694 113]\n",
      " [371 435]]\n",
      "bw = 10, f1_w score = 0.6919968059185193\n",
      "\n",
      "best outer bw = 1.0, best outer f1_w score = 0.8509410261068961\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[806   1]\n",
      " [229 577]]\n",
      "bw = 0.001, f1_w score = 0.8544753754714969\n",
      "[[806   1]\n",
      " [229 577]]\n",
      "bw = 0.005, f1_w score = 0.8544753754714969\n",
      "[[806   1]\n",
      " [230 576]]\n",
      "bw = 0.01, f1_w score = 0.8538163397177335\n",
      "[[806   1]\n",
      " [236 570]]\n",
      "bw = 0.05, f1_w score = 0.8498546585270729\n",
      "[[806   1]\n",
      " [248 558]]\n",
      "bw = 0.1, f1_w score = 0.8418916924021707\n",
      "[[796  11]\n",
      " [206 600]]\n",
      "bw = 1, f1_w score = 0.8634518928918491\n",
      "[[744  63]\n",
      " [298 508]]\n",
      "bw = 3, f1_w score = 0.7712976022290012\n",
      "[[683 124]\n",
      " [307 499]]\n",
      "bw = 5, f1_w score = 0.7292731490513892\n",
      "[[689 118]\n",
      " [328 478]]\n",
      "bw = 7, f1_w score = 0.7186827401957104\n",
      "[[700 107]\n",
      " [351 455]]\n",
      "bw = 10, f1_w score = 0.709351531861588\n",
      "\n",
      "best outer bw = 1.0, best outer f1_w score = 0.8578102961918195\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[807   0]\n",
      " [252 554]]\n",
      "bw = 0.001, f1_w score = 0.8398288254208437\n",
      "[[807   0]\n",
      " [252 554]]\n",
      "bw = 0.005, f1_w score = 0.8398288254208437\n",
      "[[807   0]\n",
      " [252 554]]\n",
      "bw = 0.01, f1_w score = 0.8398288254208437\n",
      "[[807   0]\n",
      " [260 546]]\n",
      "bw = 0.05, f1_w score = 0.8344758230030376\n",
      "[[807   0]\n",
      " [273 533]]\n",
      "bw = 0.1, f1_w score = 0.8257212095019062\n",
      "[[804   3]\n",
      " [233 573]]\n",
      "bw = 1, f1_w score = 0.8506251746188209\n",
      "[[691 116]\n",
      " [268 538]]\n",
      "bw = 3, f1_w score = 0.7597728788842519\n",
      "[[689 118]\n",
      " [342 464]]\n",
      "bw = 5, f1_w score = 0.7091579307165727\n",
      "[[700 107]\n",
      " [367 439]]\n",
      "bw = 7, f1_w score = 0.6982366927055377\n",
      "[[689 118]\n",
      " [372 434]]\n",
      "bw = 10, f1_w score = 0.6884313119494913\n",
      "\n",
      "best outer bw = 1.0, best outer f1_w score = 0.8386852657408079\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[807   0]\n",
      " [273 533]]\n",
      "bw = 0.001, f1_w score = 0.8257212095019062\n",
      "[[807   0]\n",
      " [273 533]]\n",
      "bw = 0.005, f1_w score = 0.8257212095019062\n",
      "[[807   0]\n",
      " [273 533]]\n",
      "bw = 0.01, f1_w score = 0.8257212095019062\n",
      "[[807   0]\n",
      " [278 528]]\n",
      "bw = 0.05, f1_w score = 0.8223348685065501\n",
      "[[807   0]\n",
      " [299 507]]\n",
      "bw = 0.1, f1_w score = 0.8079891104635817\n",
      "[[803   4]\n",
      " [265 541]]\n",
      "bw = 1, f1_w score = 0.8287107821366888\n",
      "[[778  29]\n",
      " [361 445]]\n",
      "bw = 3, f1_w score = 0.7474507001541624\n",
      "[[689 118]\n",
      " [352 454]]\n",
      "bw = 5, f1_w score = 0.7022984876758462\n",
      "[[693 114]\n",
      " [384 422]]\n",
      "bw = 7, f1_w score = 0.6822904306719697\n",
      "[[685 122]\n",
      " [386 420]]\n",
      "bw = 10, f1_w score = 0.6763224340560544\n",
      "\n",
      "best outer bw = 1.0, best outer f1_w score = 0.8467717116522995\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[807   0]\n",
      " [262 544]]\n",
      "bw = 0.001, f1_w score = 0.8331335386559267\n",
      "[[807   0]\n",
      " [263 543]]\n",
      "bw = 0.005, f1_w score = 0.8324617813151516\n",
      "[[807   0]\n",
      " [263 543]]\n",
      "bw = 0.01, f1_w score = 0.8324617813151516\n",
      "[[807   0]\n",
      " [270 536]]\n",
      "bw = 0.05, f1_w score = 0.8277478238582968\n",
      "[[807   0]\n",
      " [278 528]]\n",
      "bw = 0.1, f1_w score = 0.8223348685065501\n",
      "[[803   4]\n",
      " [242 564]]\n",
      "bw = 1, f1_w score = 0.8440656625199242\n",
      "[[752  55]\n",
      " [311 495]]\n",
      "bw = 3, f1_w score = 0.7671832852207656\n",
      "[[687 120]\n",
      " [322 484]]\n",
      "bw = 5, f1_w score = 0.7215663761052269\n",
      "[[709  98]\n",
      " [361 445]]\n",
      "bw = 7, f1_w score = 0.707604401610854\n",
      "[[702 105]\n",
      " [364 442]]\n",
      "bw = 10, f1_w score = 0.7014812350715363\n",
      "\n",
      "best outer bw = 1.0, best outer f1_w score = 0.8376038258243141\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[806   0]\n",
      " [234 573]]\n",
      "bw = 0.001, f1_w score = 0.851837109614207\n",
      "[[806   0]\n",
      " [234 573]]\n",
      "bw = 0.005, f1_w score = 0.851837109614207\n",
      "[[806   0]\n",
      " [234 573]]\n",
      "bw = 0.01, f1_w score = 0.851837109614207\n",
      "[[806   0]\n",
      " [243 564]]\n",
      "bw = 0.05, f1_w score = 0.845879903507582\n",
      "[[806   0]\n",
      " [266 541]]\n",
      "bw = 0.1, f1_w score = 0.8305152902734458\n",
      "[[801   5]\n",
      " [224 583]]\n",
      "bw = 1, f1_w score = 0.8553870126005925\n",
      "[[655 151]\n",
      " [239 568]]\n",
      "bw = 3, f1_w score = 0.7575090586693392\n",
      "[[752  54]\n",
      " [405 402]]\n",
      "bw = 5, f1_w score = 0.7013768977872108\n",
      "[[703 103]\n",
      " [383 424]]\n",
      "bw = 7, f1_w score = 0.6894055614898682\n",
      "[[667 139]\n",
      " [365 442]]\n",
      "bw = 10, f1_w score = 0.6813382545242448\n",
      "\n",
      "best outer bw = 1.0, best outer f1_w score = 0.8513384461827174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kde_params = {\n",
    "    'BANDWIDTH' : [0.001, 0.005, 0.01, 0.05, 0.1, 1, 3, 5, 7, 10]\n",
    "}         \n",
    "#CI = 0.95\n",
    "\n",
    "test_metrics = classic_cross_val(model=\"kde\", params=kde_params, apply_std=True, apply_minmax=False, \n",
    "                                 dim_red=\"pca\", n_folds=10)\n",
    "                                 \n",
    "\n",
    "#test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "262416b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BANDWIDTH      F1_W      F1_0      F1_1  RECALL_0  PRECISION_0       FPR  \\\n",
      "8        1.0  0.837604  0.862069  0.813139  0.992556     0.761905  0.238095   \n",
      "6        1.0  0.838685  0.863588  0.813783  0.997519     0.761364  0.238636   \n",
      "7        1.0  0.846772  0.868906  0.824638  0.995037     0.771154  0.228846   \n",
      "1        1.0  0.849359  0.870933  0.827786  0.996278     0.773603  0.226397   \n",
      "4        1.0  0.850941  0.871179  0.830703  0.990074     0.777778  0.222222   \n",
      "9        1.0  0.851338  0.872352  0.830325  0.995043     0.776596  0.223404   \n",
      "3        1.0  0.854414  0.873007  0.835821  0.983891     0.784585  0.215415   \n",
      "5        1.0  0.857810  0.875000  0.840621  0.981390     0.789421  0.210579   \n",
      "2        1.0  0.863666  0.881838  0.845494  0.998761     0.789422  0.210578   \n",
      "0        1.0  0.871144  0.886552  0.855735  0.992565     0.801000  0.199000   \n",
      "\n",
      "   HYPER_F1_W      EPI_W            SCALER                     PCA  \\\n",
      "8    0.844066 -42.038926  StandardScaler()  PCA(n_components=0.99)   \n",
      "6    0.850625 -41.198963  StandardScaler()  PCA(n_components=0.99)   \n",
      "7    0.828711 -41.039551  StandardScaler()  PCA(n_components=0.99)   \n",
      "1    0.846167 -42.174030  StandardScaler()  PCA(n_components=0.99)   \n",
      "4    0.863193 -41.833932  StandardScaler()  PCA(n_components=0.99)   \n",
      "9    0.855387 -41.970976  StandardScaler()  PCA(n_components=0.99)   \n",
      "3    0.844020 -41.594420  StandardScaler()  PCA(n_components=0.99)   \n",
      "5    0.863452 -41.625866  StandardScaler()  PCA(n_components=0.99)   \n",
      "2    0.848093 -41.999832  StandardScaler()  PCA(n_components=0.99)   \n",
      "0    0.837013 -41.042612  StandardScaler()  PCA(n_components=0.99)   \n",
      "\n",
      "             MODEL  TRAINING TIME  TESTING TIME  \n",
      "8  KernelDensity()      47.827594    202.503639  \n",
      "6  KernelDensity()      50.093318    205.920109  \n",
      "7  KernelDensity()      51.293195    203.944728  \n",
      "1  KernelDensity()      44.484772    127.494774  \n",
      "4  KernelDensity()      51.524732    206.601977  \n",
      "9  KernelDensity()      46.297964    203.641473  \n",
      "3  KernelDensity()      51.147464    205.726575  \n",
      "5  KernelDensity()      51.202360    206.374852  \n",
      "2  KernelDensity()      44.352095    207.051249  \n",
      "0  KernelDensity()      42.906781    180.318310  \n",
      "Average F1 Score: 0.8521733544550939 +/- 0.006408759716863184\n",
      "Average FPR: 0.22131728771840975 +/- 0.007819845087039002\n",
      "Average Training Time: 48.113027556805164 +/- 2.0887521892812817\n",
      "Average Testing Time\": 194.95776862321537 +/- 15.497645967817778\n"
     ]
    }
   ],
   "source": [
    "average_f1score, confidence_int_f1_score, average_fpr, confidence_int_fpr, average_training_time, confidence_int_training_time, average_testing_time, confidence_int_testing_time = confidence_interval(test_metrics, 0.95)\n",
    "print(f'Average F1 Score: {average_f1score} +/- {confidence_int_f1_score}')\n",
    "print(f'Average FPR: {average_fpr} +/- {confidence_int_fpr}')\n",
    "print(f'Average Training Time: {average_training_time} +/- {confidence_int_training_time}')\n",
    "print(f'Average Testing Time\": {average_testing_time} +/- {confidence_int_testing_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6d099",
   "metadata": {},
   "source": [
    "### One more test model in unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce3b9f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Score Weighted in Test Set:  0.9953702711392134\n",
      "False Positive Rate in Test set:  0.0\n"
     ]
    }
   ],
   "source": [
    "best_bw = test_metrics.iloc[-1]['BANDWIDTH']\n",
    "best_epi = test_metrics.iloc[-1]['EPI_W']\n",
    "best_scaler = test_metrics.iloc[-1]['SCALER']\n",
    "best_pca = test_metrics.iloc[-1]['PCA']\n",
    "best_model = test_metrics.iloc[-1]['MODEL']\n",
    "#outer_metrics.iloc[-1]\n",
    "\n",
    "#scale data\n",
    "x_test_scaled = best_scaler.transform(x_test)\n",
    "\n",
    "# apply pca to dataz\n",
    "x_test_pca =best_pca.transform(x_test_scaled) #:q  \n",
    "#x_test_pca = x_test_scaled\n",
    "\n",
    "# test best model with best parameters\n",
    "scores = best_model.score_samples(x_test_pca)         \n",
    "\n",
    "# test model with unseen data\n",
    "f1_0, f1_1, f1_w, recall_0, precision_0, FPR2, precision_w, recall_w = test_threshold(scores, y_test, best_epi)  # ?T?T ?T\n",
    "\n",
    "print(\"F1 Score Weighted in Test Set: \", f1_w)    \n",
    "print(\"False Positive Rate in Test set: \", FPR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0d9b9d",
   "metadata": {},
   "source": [
    "# Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dd3c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0df15109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lof_hyperparam_search(xnormal_train, xval, yval, params, metrics, metrics_column):\n",
    "    # search for best 'bw' hyper-parameter\n",
    "    for nn in params['N_NEIGHBORS']:   \n",
    "        #fit KDE\n",
    "        lof = LocalOutlierFactor(n_neighbors=nn, contamination=0.5, novelty=True).fit(xnormal_train)       \n",
    "        # cross-validation\n",
    "        scores = lof.score_samples(xval)\n",
    "        # fetch performance metrics from KDE threshold\n",
    "        f1_w, epi_w = val_threshold(scores, yval, step_resolution=STEP_RESOLUTION)\n",
    "        # save metrics\n",
    "        metrics = metrics.append(pd.DataFrame([[nn, f1_w,  epi_w]], columns=metrics_column), ignore_index=True)  \n",
    "        #\n",
    "        print(\"nn = {}, f1_w score = {}\".format( nn, f1_w))\n",
    "    #      \n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5290afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lof_test_best_model(cv_type, best_row, xnormal_train, xtest, ytest, metrics, metrics_column, scaler, pca, training_time):\n",
    "    if cv_type == \"classic\":\n",
    "        best_nn, best_f1, best_epi = best_row['N_NEIGHBORS'], best_row['F1_W'], best_row['EPI_W']  \n",
    "    else:\n",
    "        best_nn, best_f1, best_epi = best_row['N_NEIGHBORS'], best_row['F1_W_MEAN'], best_row['EPI_W_MEAN']     \n",
    "\n",
    "    # \n",
    "    start_time = time.time()\n",
    "    # run model with best parameters to date...a\n",
    "    lof = LocalOutlierFactor(n_neighbors=best_nn, contamination=0.5, novelty=True).fit(xnormal_train)\n",
    "    # test \n",
    "    scores = lof.score_samples(xtest)\n",
    "    # fetch performance metrics from threshold...\n",
    "    f1_0, f1_1, f1_w, recall_0, precision_0, FPR, precision_w, recall_w\\\n",
    "        = test_threshold(scores, ytest, best_epi)\n",
    "    #\n",
    "    end_time = 254/(time.time() - start_time)\n",
    "    #\n",
    "    metrics = metrics.append(pd.DataFrame([[best_nn, f1_w, f1_0, f1_1, recall_0, precision_0, FPR, best_f1, best_epi,  scaler, pca, lof, training_time, end_time]], columns=metrics_column), ignore_index=True)\n",
    "    print(\"best outer nn = {}, best outer f1_w score = {}\\n\".format(best_nn, f1_w))\n",
    "    \n",
    "    return metrics\n",
    "    #g_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7b3309e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3228, 150)\n",
      "[[743  64]\n",
      " [136 671]]\n",
      "nn = 2, f1_w score = 0.8758371759188741\n",
      "[[763  44]\n",
      " [ 57 750]]\n",
      "nn = 5, f1_w score = 0.9374184926676512\n",
      "[[760  47]\n",
      " [ 55 752]]\n",
      "nn = 7, f1_w score = 0.9368014213038958\n",
      "[[781  26]\n",
      " [ 86 721]]\n",
      "nn = 10, f1_w score = 0.9305111563176078\n",
      "[[760  47]\n",
      " [ 93 714]]\n",
      "nn = 15, f1_w score = 0.9131884681583476\n",
      "[[752  55]\n",
      " [109 698]]\n",
      "nn = 20, f1_w score = 0.8982752259730677\n",
      "[[759  48]\n",
      " [132 675]]\n",
      "nn = 25, f1_w score = 0.8881729370193306\n",
      "[[725  82]\n",
      " [113 694]]\n",
      "nn = 30, f1_w score = 0.8791375691954986\n",
      "[[730  77]\n",
      " [134 673]]\n",
      "nn = 35, f1_w score = 0.8691056432466338\n",
      "[[787  20]\n",
      " [202 605]]\n",
      "nn = 40, f1_w score = 0.8606820246108671\n",
      "[[737  70]\n",
      " [160 647]]\n",
      "nn = 45, f1_w score = 0.8570524195039\n",
      "[[779  28]\n",
      " [205 602]]\n",
      "nn = 50, f1_w score = 0.8538808633750987\n",
      "\n",
      "best outer nn = 5, best outer f1_w score = 0.9306070805591726\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[787  20]\n",
      " [214 592]]\n",
      "nn = 2, f1_w score = 0.8527770323402024\n",
      "[[773  34]\n",
      " [ 73 733]]\n",
      "nn = 5, f1_w score = 0.933623160648404\n",
      "[[779  28]\n",
      " [ 83 723]]\n",
      "nn = 7, f1_w score = 0.9311010827615904\n",
      "[[790  17]\n",
      " [115 691]]\n",
      "nn = 10, f1_w score = 0.917855467351449\n",
      "[[764  43]\n",
      " [113 693]]\n",
      "nn = 15, f1_w score = 0.903098052626228\n",
      "[[759  48]\n",
      " [139 667]]\n",
      "nn = 20, f1_w score = 0.8836885750037116\n",
      "[[741  66]\n",
      " [139 667]]\n",
      "nn = 25, f1_w score = 0.8726395672599356\n",
      "[[719  88]\n",
      " [124 682]]\n",
      "nn = 30, f1_w score = 0.8684986925088447\n",
      "[[741  66]\n",
      " [157 649]]\n",
      "nn = 35, f1_w score = 0.8612970707263512\n",
      "[[726  81]\n",
      " [155 651]]\n",
      "nn = 40, f1_w score = 0.8533717698247862\n",
      "[[720  87]\n",
      " [163 643]]\n",
      "nn = 45, f1_w score = 0.8446552946252466\n",
      "[[770  37]\n",
      " [222 584]]\n",
      "nn = 50, f1_w score = 0.8372657393950466\n",
      "\n",
      "best outer nn = 5, best outer f1_w score = 0.931168890582129\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[767  40]\n",
      " [196 610]]\n",
      "nn = 2, f1_w score = 0.8522893772893774\n",
      "[[767  40]\n",
      " [113 693]]\n",
      "nn = 5, f1_w score = 0.9049456282476592\n",
      "[[747  60]\n",
      " [ 47 759]]\n",
      "nn = 7, f1_w score = 0.933660308461058\n",
      "[[741  66]\n",
      " [ 45 761]]\n",
      "nn = 10, f1_w score = 0.9311735474667376\n",
      "[[773  34]\n",
      " [106 700]]\n",
      "nn = 15, f1_w score = 0.9130270678313382\n",
      "[[775  32]\n",
      " [119 687]]\n",
      "nn = 20, f1_w score = 0.906106147781922\n",
      "[[730  77]\n",
      " [ 89 717]]\n",
      "nn = 25, f1_w score = 0.8970794895448955\n",
      "[[738  69]\n",
      " [108 698]]\n",
      "nn = 30, f1_w score = 0.8901990601380141\n",
      "[[756  51]\n",
      " [140 666]]\n",
      "nn = 35, f1_w score = 0.8812173025933534\n",
      "[[764  43]\n",
      " [172 634]]\n",
      "nn = 40, f1_w score = 0.8658365278859393\n",
      "[[741  66]\n",
      " [160 646]]\n",
      "nn = 45, f1_w score = 0.8594006967135976\n",
      "[[740  67]\n",
      " [167 639]]\n",
      "nn = 50, f1_w score = 0.8543576707228983\n",
      "\n",
      "best outer nn = 7, best outer f1_w score = 0.9330437857450342\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[757  50]\n",
      " [153 653]]\n",
      "nn = 2, f1_w score = 0.8736221768592483\n",
      "[[770  37]\n",
      " [107 699]]\n",
      "nn = 5, f1_w score = 0.9105520485780567\n",
      "[[743  64]\n",
      " [ 42 764]]\n",
      "nn = 7, f1_w score = 0.9342728021994919\n",
      "[[737  70]\n",
      " [ 41 765]]\n",
      "nn = 10, f1_w score = 0.9311633861786976\n",
      "[[735  72]\n",
      " [ 72 734]]\n",
      "nn = 15, f1_w score = 0.9107253221655429\n",
      "[[728  79]\n",
      " [ 82 724]]\n",
      "nn = 20, f1_w score = 0.9001853750144615\n",
      "[[740  67]\n",
      " [102 704]]\n",
      "nn = 25, f1_w score = 0.8951740702556804\n",
      "[[732  75]\n",
      " [108 698]]\n",
      "nn = 30, f1_w score = 0.8864963760467244\n",
      "[[769  38]\n",
      " [157 649]]\n",
      "nn = 35, f1_w score = 0.8784344250858691\n",
      "[[772  35]\n",
      " [176 630]]\n",
      "nn = 40, f1_w score = 0.8681661214631983\n",
      "[[758  49]\n",
      " [167 639]]\n",
      "nn = 45, f1_w score = 0.8653551851748795\n",
      "[[758  49]\n",
      " [174 632]]\n",
      "nn = 50, f1_w score = 0.8608995035757474\n",
      "\n",
      "best outer nn = 7, best outer f1_w score = 0.9386213234658215\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[759  47]\n",
      " [198 609]]\n",
      "nn = 2, f1_w score = 0.8467841082105045\n",
      "[[786  20]\n",
      " [147 660]]\n",
      "nn = 5, f1_w score = 0.8958305699423758\n",
      "[[735  71]\n",
      " [ 56 751]]\n",
      "nn = 7, f1_w score = 0.921256976228833\n",
      "[[733  73]\n",
      " [ 65 742]]\n",
      "nn = 10, f1_w score = 0.9144424696581605\n",
      "[[771  35]\n",
      " [128 679]]\n",
      "nn = 15, f1_w score = 0.8986162445219518\n",
      "[[732  74]\n",
      " [106 701]]\n",
      "nn = 20, f1_w score = 0.8883654618103298\n",
      "[[770  36]\n",
      " [160 647]]\n",
      "nn = 25, f1_w score = 0.8777765750162373\n",
      "[[732  74]\n",
      " [136 671]]\n",
      "nn = 30, f1_w score = 0.8696213464878247\n",
      "[[715  91]\n",
      " [125 682]]\n",
      "nn = 35, f1_w score = 0.866031960871772\n",
      "[[761  45]\n",
      " [193 614]]\n",
      "nn = 40, f1_w score = 0.8512131030633758\n",
      "[[753  53]\n",
      " [188 619]]\n",
      "nn = 45, f1_w score = 0.8495506447254503\n",
      "[[756  50]\n",
      " [206 601]]\n",
      "nn = 50, f1_w score = 0.8398103147558484\n",
      "\n",
      "best outer nn = 7, best outer f1_w score = 0.9392043653907098\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[774  33]\n",
      " [186 620]]\n",
      "nn = 2, f1_w score = 0.8629791551996797\n",
      "[[787  20]\n",
      " [149 657]]\n",
      "nn = 5, f1_w score = 0.8945412707568546\n",
      "[[766  41]\n",
      " [ 78 728]]\n",
      "nn = 7, f1_w score = 0.9261834578370012\n",
      "[[738  69]\n",
      " [ 48 758]]\n",
      "nn = 10, f1_w score = 0.927453198681156\n",
      "[[759  48]\n",
      " [103 703]]\n",
      "nn = 15, f1_w score = 0.9062726441171185\n",
      "[[768  39]\n",
      " [132 674]]\n",
      "nn = 20, f1_w score = 0.8936250955963767\n",
      "[[758  49]\n",
      " [130 676]]\n",
      "nn = 25, f1_w score = 0.888739116277367\n",
      "[[736  71]\n",
      " [123 683]]\n",
      "nn = 30, f1_w score = 0.8795972235047864\n",
      "[[769  38]\n",
      " [177 629]]\n",
      "nn = 35, f1_w score = 0.8656962421901897\n",
      "[[768  39]\n",
      " [185 621]]\n",
      "nn = 40, f1_w score = 0.8599652734714127\n",
      "[[780  27]\n",
      " [201 605]]\n",
      "nn = 45, f1_w score = 0.8569648374420102\n",
      "[[775  32]\n",
      " [195 611]]\n",
      "nn = 50, f1_w score = 0.8577984234562248\n",
      "\n",
      "best outer nn = 10, best outer f1_w score = 0.9193527295999213\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[777  30]\n",
      " [180 626]]\n",
      "nn = 2, f1_w score = 0.868656765031594\n",
      "[[740  67]\n",
      " [ 36 770]]\n",
      "nn = 5, f1_w score = 0.936121734697134\n",
      "[[759  48]\n",
      " [ 49 757]]\n",
      "nn = 7, f1_w score = 0.9398635157287458\n",
      "[[779  28]\n",
      " [ 97 709]]\n",
      "nn = 10, f1_w score = 0.9223584247029788\n",
      "[[752  55]\n",
      " [ 88 718]]\n",
      "nn = 15, f1_w score = 0.9113059113370579\n",
      "[[759  48]\n",
      " [109 697]]\n",
      "nn = 20, f1_w score = 0.9025218202988925\n",
      "[[747  60]\n",
      " [118 688]]\n",
      "nn = 25, f1_w score = 0.8894987776566724\n",
      "[[741  66]\n",
      " [131 675]]\n",
      "nn = 30, f1_w score = 0.8776625049616676\n",
      "[[720  87]\n",
      " [129 677]]\n",
      "nn = 35, f1_w score = 0.8659927997784547\n",
      "[[757  50]\n",
      " [187 619]]\n",
      "nn = 40, f1_w score = 0.8519854030142582\n",
      "[[756  51]\n",
      " [197 609]]\n",
      "nn = 45, f1_w score = 0.8449615527719212\n",
      "[[732  75]\n",
      " [180 626]]\n",
      "nn = 50, f1_w score = 0.8412237944855365\n",
      "\n",
      "best outer nn = 7, best outer f1_w score = 0.9342837156386445\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[758  49]\n",
      " [144 662]]\n",
      "nn = 2, f1_w score = 0.8799218376634923\n",
      "[[761  46]\n",
      " [ 75 731]]\n",
      "nn = 5, f1_w score = 0.9249585427024584\n",
      "[[761  46]\n",
      " [ 60 746]]\n",
      "nn = 7, f1_w score = 0.9342782593721267\n",
      "[[734  73]\n",
      " [ 42 764]]\n",
      "nn = 10, f1_w score = 0.9286796067006835\n",
      "[[733  74]\n",
      " [ 48 758]]\n",
      "nn = 15, f1_w score = 0.9243463645226868\n",
      "[[756  51]\n",
      " [ 92 714]]\n",
      "nn = 20, f1_w score = 0.9112851706054412\n",
      "[[733  74]\n",
      " [ 92 714]]\n",
      "nn = 25, f1_w score = 0.8970718933746649\n",
      "[[736  71]\n",
      " [103 703]]\n",
      "nn = 30, f1_w score = 0.8920813018133718\n",
      "[[729  78]\n",
      " [134 672]]\n",
      "nn = 35, f1_w score = 0.8684035527915891\n",
      "[[713  94]\n",
      " [130 676]]\n",
      "nn = 40, f1_w score = 0.8610552222734964\n",
      "[[740  67]\n",
      " [162 644]]\n",
      "nn = 45, f1_w score = 0.8575238384711904\n",
      "[[733  74]\n",
      " [166 640]]\n",
      "nn = 50, f1_w score = 0.8507126550256061\n",
      "\n",
      "best outer nn = 7, best outer f1_w score = 0.9231222191131296\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[750  57]\n",
      " [156 650]]\n",
      "nn = 2, f1_w score = 0.8674384175441561\n",
      "[[772  35]\n",
      " [103 703]]\n",
      "nn = 5, f1_w score = 0.9142882886768158\n",
      "[[741  66]\n",
      " [ 45 761]]\n",
      "nn = 7, f1_w score = 0.9311735474667376\n",
      "[[722  85]\n",
      " [ 55 751]]\n",
      "nn = 10, f1_w score = 0.9131771429274473\n",
      "[[715  92]\n",
      " [ 65 741]]\n",
      "nn = 15, f1_w score = 0.9026405438021632\n",
      "[[740  67]\n",
      " [112 694]]\n",
      "nn = 20, f1_w score = 0.8889363311180376\n",
      "[[755  52]\n",
      " [142 664]]\n",
      "nn = 25, f1_w score = 0.8793431857020353\n",
      "[[727  80]\n",
      " [119 687]]\n",
      "nn = 30, f1_w score = 0.8765514856918916\n",
      "[[758  49]\n",
      " [176 630]]\n",
      "nn = 35, f1_w score = 0.8596243886307069\n",
      "[[753  54]\n",
      " [189 617]]\n",
      "nn = 40, f1_w score = 0.8482703918633454\n",
      "[[709  98]\n",
      " [150 656]]\n",
      "nn = 45, f1_w score = 0.846083048604057\n",
      "[[694 113]\n",
      " [144 662]]\n",
      "nn = 50, f1_w score = 0.8406068261209769\n",
      "\n",
      "best outer nn = 7, best outer f1_w score = 0.9330304008857315\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "[[758  48]\n",
      " [148 659]]\n",
      "nn = 2, f1_w score = 0.8780278151582119\n",
      "[[782  24]\n",
      " [111 696]]\n",
      "nn = 5, f1_w score = 0.9160664252981356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[752  54]\n",
      " [ 53 754]]\n",
      "nn = 7, f1_w score = 0.9336638781750082\n",
      "[[770  36]\n",
      " [ 70 737]]\n",
      "nn = 10, f1_w score = 0.9342564252426289\n",
      "[[732  74]\n",
      " [ 58 749]]\n",
      "nn = 15, f1_w score = 0.9181558189953412\n",
      "[[736  70]\n",
      " [ 86 721]]\n",
      "nn = 20, f1_w score = 0.9032774383212431\n",
      "[[731  75]\n",
      " [111 696]]\n",
      "nn = 25, f1_w score = 0.8846325999483184\n",
      "[[733  73]\n",
      " [123 684]]\n",
      "nn = 30, f1_w score = 0.8783750511662836\n",
      "[[746  60]\n",
      " [153 654]]\n",
      "nn = 35, f1_w score = 0.8675169330256178\n",
      "[[752  54]\n",
      " [175 632]]\n",
      "nn = 40, f1_w score = 0.8572383761264821\n",
      "[[739  67]\n",
      " [176 631]]\n",
      "nn = 45, f1_w score = 0.8486706137395974\n",
      "[[748  58]\n",
      " [195 612]]\n",
      "nn = 50, f1_w score = 0.8420263750675983\n",
      "\n",
      "best outer nn = 10, best outer f1_w score = 0.932382472062393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lof_params = {\n",
    "    'N_NEIGHBORS' : [2, 5, 7, 10, 15, 20, 25, 30, 35, 40, 45, 50],    \n",
    "} \n",
    "\n",
    "STEP_RESOLUTION = 1000\n",
    "\n",
    "#outer_metrics   FalseTrue  FalseTrue  FalseTrue FalseTrue  FalseTrue FalseTrue#   no\n",
    "test_metrics = classic_cross_val(model=\"lof\", params=lof_params, apply_std=True, apply_minmax=False,\n",
    "                                dim_red=\"pca\", n_folds=10) \n",
    "\n",
    "#test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dee92d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N_NEIGHBORS      F1_W      F1_0      F1_1  RECALL_0  PRECISION_0       FPR  \\\n",
      "5          10  0.919353  0.917303  0.921403  0.894541     0.941253  0.058747   \n",
      "7           7  0.923122  0.923551  0.922693  0.929280     0.917892  0.082108   \n",
      "0           5  0.930607  0.930521  0.930693  0.929368     0.931677  0.068323   \n",
      "1           5  0.931169  0.932193  0.930145  0.946650     0.918171  0.081829   \n",
      "9          10  0.932382  0.934059  0.930706  0.956629     0.912530  0.087470   \n",
      "8           7  0.933030  0.932075  0.933985  0.919355     0.945153  0.054847   \n",
      "2           7  0.933044  0.932919  0.933168  0.931762     0.934080  0.065920   \n",
      "6           7  0.934284  0.934161  0.934406  0.933002     0.935323  0.064677   \n",
      "3           7  0.938621  0.938241  0.939002  0.933002     0.943538  0.056462   \n",
      "4           7  0.939204  0.937659  0.940750  0.913259     0.963399  0.036601   \n",
      "\n",
      "   HYPER_F1_W     EPI_W            SCALER                     PCA  \\\n",
      "5    0.927453 -1.644319  StandardScaler()  PCA(n_components=0.99)   \n",
      "7    0.934278 -2.499842  StandardScaler()  PCA(n_components=0.99)   \n",
      "0    0.937418 -3.092046  StandardScaler()  PCA(n_components=0.99)   \n",
      "1    0.933623 -3.349296  StandardScaler()  PCA(n_components=0.99)   \n",
      "9    0.934256 -1.960634  StandardScaler()  PCA(n_components=0.99)   \n",
      "8    0.931174 -1.931341  StandardScaler()  PCA(n_components=0.99)   \n",
      "2    0.933660 -2.336021  StandardScaler()  PCA(n_components=0.99)   \n",
      "6    0.939864 -2.153627  StandardScaler()  PCA(n_components=0.99)   \n",
      "3    0.934273 -2.048622  StandardScaler()  PCA(n_components=0.99)   \n",
      "4    0.921257 -1.998873  StandardScaler()  PCA(n_components=0.99)   \n",
      "\n",
      "                                               MODEL  TRAINING TIME  \\\n",
      "5  LocalOutlierFactor(contamination=0.5, n_neighb...      27.771161   \n",
      "7  LocalOutlierFactor(contamination=0.5, n_neighb...      28.252714   \n",
      "0  LocalOutlierFactor(contamination=0.5, n_neighb...      25.840775   \n",
      "1  LocalOutlierFactor(contamination=0.5, n_neighb...      24.910437   \n",
      "9  LocalOutlierFactor(contamination=0.5, n_neighb...      27.497172   \n",
      "8  LocalOutlierFactor(contamination=0.5, n_neighb...      27.576942   \n",
      "2  LocalOutlierFactor(contamination=0.5, n_neighb...      27.164348   \n",
      "6  LocalOutlierFactor(contamination=0.5, n_neighb...      28.198325   \n",
      "3  LocalOutlierFactor(contamination=0.5, n_neighb...      26.716021   \n",
      "4  LocalOutlierFactor(contamination=0.5, n_neighb...      22.194404   \n",
      "\n",
      "   TESTING TIME  \n",
      "5     76.243536  \n",
      "7     77.791485  \n",
      "0     65.697556  \n",
      "1     72.882768  \n",
      "9     73.392511  \n",
      "8     74.464300  \n",
      "2     72.498535  \n",
      "6     77.626963  \n",
      "3     59.563938  \n",
      "4     61.281187  \n",
      "Average F1 Score: 0.9314816983042686 +/- 0.0038205095360130895\n",
      "Average FPR: 0.06569841238925574 +/- 0.00948893975689235\n",
      "Average Training Time: 26.612229992983174 +/- 1.1611458792459661\n",
      "Average Testing Time\": 71.14427795060334 +/- 4.101890605525745\n"
     ]
    }
   ],
   "source": [
    "average_f1score, confidence_int_f1_score, average_fpr, confidence_int_fpr, average_training_time, confidence_int_training_time, average_testing_time, confidence_int_testing_time = confidence_interval(test_metrics, 0.95)\n",
    "print(f'Average F1 Score: {average_f1score} +/- {confidence_int_f1_score}')\n",
    "print(f'Average FPR: {average_fpr} +/- {confidence_int_fpr}')\n",
    "print(f'Average Training Time: {average_training_time} +/- {confidence_int_training_time}')\n",
    "print(f'Average Testing Time\": {average_testing_time} +/- {confidence_int_testing_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb19afa",
   "metadata": {},
   "source": [
    "#### Test model on new and unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae514f28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Score Weighted in Test Set:  0.9598653161179684\n",
      "False Positive Rate in Test set:  0.0\n"
     ]
    }
   ],
   "source": [
    "best_bw = test_metrics.iloc[-1]['N_NEIGHBORS']\n",
    "best_epi = test_metrics.iloc[-1]['EPI_W']\n",
    "best_scaler = test_metrics.iloc[-1]['SCALER']\n",
    "best_pca = test_metrics.iloc[-1]['PCA']\n",
    "best_model = test_metrics.iloc[-1]['MODEL']\n",
    "#outer_metrics.iloc[-1]\n",
    "\n",
    "#scale data\n",
    "x_test_scaled = best_scaler.transform(x_test)\n",
    "\n",
    "# apply pca to dataz\n",
    "x_test_pca = best_pca.transform(x_test_scaled) #:q  \n",
    "#x_test_pca = x_test_scaled\n",
    "\n",
    "# test best model with best parameters\n",
    "scores = best_model.score_samples(x_test_pca)         \n",
    "\n",
    "# test model with unseen data\n",
    "f1_0, f1_1, f1_w, recall_0, precision_0, FPR2, precision_w, recall_w = test_threshold(scores, y_test, best_epi)  # ?T?T ?T\n",
    "\n",
    "print(\"F1 Score Weighted in Test Set: \", f1_w)    \n",
    "print(\"False Positive Rate in Test set: \", FPR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a952622b",
   "metadata": {},
   "source": [
    "# One-Class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62131b64",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Notes: <br>\n",
    "<font size=3>$min_{w, \\xi, \\rho} \\frac{1}{2}||w||^2 + \\frac{1}{\\nu n}\\sum_i \\xi_i - \\rho$ </font> <br>\n",
    "- $\\frac{1}{\\nu n}$: how many slack variables / outliers we allow... regularization <br>\n",
    "- $\\sum_i \\xi_i$: slack variables that are penalized in the objective function...<br>\n",
    "<br> <br>\n",
    "<b>Poly kernel</b>: $(\\gamma ab+r)^d$ <br>\n",
    "    - a e b: measures <br>\n",
    "    - r: poly coeficient (coef0) <br>\n",
    "    - $\\gamma$: $\\frac{1}{\\sigma}$ <br>\n",
    "    - d: kernel degree <br> <br>\n",
    "<b>RBF kernel </b>: $\\exp{(-\\gamma*|u-v|^2)}$\n",
    "<br> <br>\n",
    "https://www.researchgate.net/figure/Calculation-of-sensitivity-specificity-and-positive-and-negative-predictive_fig1_49650721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbe6b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a783c3",
   "metadata": {},
   "source": [
    "### Parameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede93166",
   "metadata": {},
   "source": [
    "### Hyper-parameter optimization and model testing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c94720cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocsvm_hyperparam_search(xnormal_train, xval, yval, params, metrics, metrics_column):\n",
    "    #\n",
    "    kernel = params['KERNEL']\n",
    "   \n",
    "    if kernel == \"linear\":\n",
    "        \n",
    "        for nu in params['NU']:\n",
    "            # search for the best parameters\n",
    "            oc_svm = OneClassSVM(kernel='linear', nu=nu).fit(xnormal_train)    \n",
    "            # make class prediction\n",
    "            prediction = [1 if i == -1 else 0 for i in oc_svm.predict(xval)]\n",
    "            # fetch performance metrics from KDE \n",
    "            f1_w = f1_score(yval, prediction, average='weighted')\n",
    "            # append results to metrics\n",
    "            metrics = metrics.append(pd.DataFrame([[kernel, nu, f1_w]], columns=metrics_column), ignore_index=True)\n",
    "            print(\"f1_w score = {}\".format(f1_w))\n",
    "    \n",
    "    if kernel == \"rbf\":\n",
    "        \n",
    "        for nu in params['NU']:\n",
    "            for gamma in params['GAMMA']:\n",
    "                # search for the best parameters\n",
    "                oc_svm = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma).fit(xnormal_train)\n",
    "                # make class prediction\n",
    "                prediction = [1 if i == -1 else 0 for i in oc_svm.predict(xval)]\n",
    "                # fetch performance metrics...\n",
    "                f1_w = f1_score(yval, prediction, average='weighted')\n",
    "                # append results to metrics\n",
    "                metrics = metrics.append(pd.DataFrame([[kernel, nu, gamma, f1_w]], columns=metrics_column), ignore_index=True)\n",
    "                print(\"f1_w score = {}, nu = {}, gamma = {}\".format(f1_w, nu, gamma))\n",
    "    \n",
    "    if kernel == \"poly\":\n",
    "        \n",
    "        for nu in params['NU']:\n",
    "            for gamma in params['GAMMA']:\n",
    "                for degree in params['DEGREE']:\n",
    "                    for coef in params['COEF']:\n",
    "                        # search for the best parameters\n",
    "                        oc_svm = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma, degree=degree, coef0=coef).fit(xnormal_train)\n",
    "                        # make class prediction\n",
    "                        prediction = [1 if i == -1 else 0 for i in oc_svm.predict(xval)]\n",
    "                        # fetch performance metrics...\n",
    "                        f1_w = f1_score(yval, prediction, average='weighted')\n",
    "                        # append results to metrics\n",
    "                        metrics = metrics.append(pd.DataFrame([kernel, [nu, gamma, degree, coef, f1_w]], columns=metrics_column), ignore_index=True)\n",
    "                        print(\"f1_w score = {}\".format(f1_w))\n",
    "    #\n",
    "    return metrics         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b975d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_metrics(y, prediction, weights=[0.5, 0.5]): ###y21y21confusion\n",
    "    \n",
    "        confusion_m = confusion_matrix(y, prediction) #s\n",
    "        precision_0 = confusion_m[0][0] / np.sum(confusion_m[:, 0]) # True Negative Rate (TNR)\n",
    "        precision_1 = confusion_m[1][1] / np.sum(confusion_m[:, 1])\n",
    "        precision_w = (weights[0]*precision_0) + (weights[1]*precision_1)\n",
    "    \n",
    "        recall_0    = confusion_m[0][0] / np.sum(confusion_m[0, :]) # True Positive Rate (TPR)\n",
    "        recall_1    = confusion_m[1][1] / np.sum(confusion_m[1, :])    \n",
    "        recall_w    = (weights[0]*recall_0) + (weights[1]*recall_1)\n",
    "        \n",
    "        FPR2 = 1-precision_0\n",
    "        \n",
    "        f1_0 = (2*precision_0*recall_0) / (precision_0 + recall_0)\n",
    "        f1_1 = (2*precision_1*recall_1) / (precision_1 + recall_1)\n",
    "        f1_w = f1_score(y, prediction, average='weighted')\n",
    "        \n",
    "        return f1_w, f1_0, f1_1, recall_0, precision_0, FPR2\n",
    "    \n",
    "def ocsvm_test_best_model(cv_type, best_row, kernel, xnormal_train, xtest, ytest, metrics, metrics_column, scaler, pca, training_time):\n",
    "    \n",
    "    oc_svm,  f1_w = None, None\n",
    "    \n",
    "    if kernel == \"linear\":\n",
    "        #\n",
    "        start_time = time.time()\n",
    "        # test OCSVM Model\n",
    "        oc_svm = OneClassSVM(kernel='linear', nu=best_row['NU']).fit(xnormal_train)     \n",
    "        # make class prediction \n",
    "        prediction = [1 if i == -1 else 0 for i in oc_svm.predict(xtest)]\n",
    "        # compute f1 score\n",
    "        f1_w, f1_0, f1_1, recall_0, precision_0, FPR2 = get_test_metrics(ytest, prediction)\n",
    "        #end\n",
    "        close_time = 254/(time.time() - start_time)\n",
    "        # append results to metrics metrics_arraymetrics_array#\n",
    "        metrics = metrics.append(pd.DataFrame([[kernel, best_row['NU'], f1_w, f1_0, f1_1, recall_0, precision_0, FPR2, best_row['F1_W'] if cv_type == \"classic\" else best_row['F1_W_MEAN'], scaler, pca , oc_svm, training_time, close_time]], columns=metrics_column), ignore_index=True)\n",
    "        \n",
    "    if kernel == \"rbf\":\n",
    "        #\n",
    "        start_time = time.time()\n",
    "        # test OCSVM Model\n",
    "        oc_svm = OneClassSVM(kernel='rbf', nu=best_row['NU'], gamma=best_row['GAMMA']).fit(xnormal_train) \n",
    "        #   make class predictions...\n",
    "        prediction = [1 if i == -1 else 0 for i in oc_svm.predict(xtest)]\n",
    "        # compute f1 score \n",
    "        f1_w, f1_0, f1_1, recall_0, precision_0, FPR2 = get_test_metrics(ytest, prediction)\n",
    "        #end\n",
    "        close_time = 254/(time.time() - start_time)\n",
    "        # append results to metrics      \n",
    "        metrics = metrics.append(pd.DataFrame([[kernel, best_row['NU'], best_row['GAMMA'], f1_w, f1_0, f1_1, recall_0, precision_0, FPR2, best_row['F1_W'] if cv_type == \"classic\" else best_row['F1_W_MEAN'], scaler, pca , oc_svm, training_time, close_time]], columns=metrics_column), ignore_index=True)\n",
    "        \n",
    "    if kernel == \"poly\":\n",
    "        #\n",
    "        start_time = time.time()\n",
    "        # test OCSVM Model\n",
    "        oc_svm = OneClassSVM(kernel='poly', nu=best_row['NU'], gamma=best_row['GAMMA'], degree=best_row['DEGREE'], coef0=best_row['COEF']).fit(xnormal_train) \n",
    "        # make class predictions...\n",
    "        prediction = [1 if i == -1 else 0 for i in oc_svm.predict(xtest)]\n",
    "        # compute f1 score \n",
    "        f1_w, f1_0, f1_1, recall_0, precision_0, FPR2 = get_test_metrics(ytest, prediction)\n",
    "        #end\n",
    "        close_time = 254/(time.time() - start_time)\n",
    "        # append results to metrics   \n",
    "        metrics = metrics.append(pd.DataFrame([[kernel, best_row['NU'], best_row['GAMMA'], best_row['DEGREE'], best_row['COEF'], f1_w, f1_0, f1_1, recall_0, precision_0, FPR2, best_row['F1_W'] if cv_type == \"classic\" else best_row['F1_W_MEAN'], scaler, pca , oc_svm, training_time, close_time]], columns=metrics_column), ignore_index=True)\n",
    "\n",
    "    print(\"best outer f1_w score = {}\\n\".format( f1_w))   \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e608a",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f4dac2",
   "metadata": {},
   "source": [
    "nu = used by all kernels, gamma = used by poly, rbf and sigmoid <br>\n",
    "degree = used by poly only, coefficient = used by poly and sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2ac880b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3228, 150)\n",
      "f1_w score = 0.8203248733208801, nu = 0.01, gamma = 0.01\n",
      "f1_w score = 0.8616269637605513, nu = 0.01, gamma = 0.05\n",
      "f1_w score = 0.8986272707831204, nu = 0.01, gamma = 0.1\n",
      "f1_w score = 0.9460245280154064, nu = 0.01, gamma = 0.5\n",
      "f1_w score = 0.8036292791321339, nu = 0.05, gamma = 0.01\n",
      "f1_w score = 0.8515167913909333, nu = 0.05, gamma = 0.05\n",
      "f1_w score = 0.881443792580286, nu = 0.05, gamma = 0.1\n",
      "f1_w score = 0.9447786181776245, nu = 0.05, gamma = 0.5\n",
      "f1_w score = 0.784897579989952, nu = 0.1, gamma = 0.01\n",
      "f1_w score = 0.8315348449186493, nu = 0.1, gamma = 0.05\n",
      "f1_w score = 0.8660967785548358, nu = 0.1, gamma = 0.1\n",
      "f1_w score = 0.9297835896831749, nu = 0.1, gamma = 0.5\n",
      "f1_w score = 0.6596195404913557, nu = 0.5, gamma = 0.01\n",
      "f1_w score = 0.6663536105605846, nu = 0.5, gamma = 0.05\n",
      "f1_w score = 0.6892967145790555, nu = 0.5, gamma = 0.1\n",
      "f1_w score = 0.7381995133819952, nu = 0.5, gamma = 0.5\n",
      "best outer f1_w score = 0.9236088049854642\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "f1_w score = 0.8111409077714031, nu = 0.01, gamma = 0.01\n",
      "f1_w score = 0.8593076247468386, nu = 0.01, gamma = 0.05\n",
      "f1_w score = 0.8991345553372829, nu = 0.01, gamma = 0.1\n",
      "f1_w score = 0.9416467452082684, nu = 0.01, gamma = 0.5\n",
      "f1_w score = 0.7955036480251545, nu = 0.05, gamma = 0.01\n",
      "f1_w score = 0.8450227068473423, nu = 0.05, gamma = 0.05\n",
      "f1_w score = 0.8844470051859744, nu = 0.05, gamma = 0.1\n",
      "f1_w score = 0.940399727219116, nu = 0.05, gamma = 0.5\n",
      "f1_w score = 0.7771847330148719, nu = 0.1, gamma = 0.01\n",
      "f1_w score = 0.830645673158895, nu = 0.1, gamma = 0.05\n",
      "f1_w score = 0.8734592064762225, nu = 0.1, gamma = 0.1\n",
      "f1_w score = 0.921626945426404, nu = 0.1, gamma = 0.5\n",
      "f1_w score = 0.6595062274164787, nu = 0.5, gamma = 0.01\n",
      "f1_w score = 0.659684016710641, nu = 0.5, gamma = 0.05\n",
      "f1_w score = 0.6798599282393072, nu = 0.5, gamma = 0.1\n",
      "f1_w score = 0.7055815184939016, nu = 0.5, gamma = 0.5\n",
      "best outer f1_w score = 0.9335370234226721\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "f1_w score = 0.8269343034848715, nu = 0.01, gamma = 0.01\n",
      "f1_w score = 0.8803879530926808, nu = 0.01, gamma = 0.05\n",
      "f1_w score = 0.9166963679846315, nu = 0.01, gamma = 0.1\n",
      "f1_w score = 0.9353823071024343, nu = 0.01, gamma = 0.5\n",
      "f1_w score = 0.8147531023251117, nu = 0.05, gamma = 0.01\n",
      "f1_w score = 0.8597894385374327, nu = 0.05, gamma = 0.05\n",
      "f1_w score = 0.9013173592352548, nu = 0.05, gamma = 0.1\n",
      "f1_w score = 0.9441221241502142, nu = 0.05, gamma = 0.5\n",
      "f1_w score = 0.8058895332113772, nu = 0.1, gamma = 0.01\n",
      "f1_w score = 0.8323895873003453, nu = 0.1, gamma = 0.05\n",
      "f1_w score = 0.8784870105383, nu = 0.1, gamma = 0.1\n",
      "f1_w score = 0.9259810213789897, nu = 0.1, gamma = 0.5\n",
      "f1_w score = 0.672779026878974, nu = 0.5, gamma = 0.01\n",
      "f1_w score = 0.6797727603334452, nu = 0.5, gamma = 0.05\n",
      "f1_w score = 0.7005381918217782, nu = 0.5, gamma = 0.1\n",
      "f1_w score = 0.7205423045288677, nu = 0.5, gamma = 0.5\n",
      "best outer f1_w score = 0.9391580548695142\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "f1_w score = 0.8283713394257061, nu = 0.01, gamma = 0.01\n",
      "f1_w score = 0.8727255857502635, nu = 0.01, gamma = 0.05\n",
      "f1_w score = 0.9078807628416589, nu = 0.01, gamma = 0.1\n",
      "f1_w score = 0.9385095267963919, nu = 0.01, gamma = 0.5\n",
      "f1_w score = 0.8159248929112212, nu = 0.05, gamma = 0.01\n",
      "f1_w score = 0.8613901755552904, nu = 0.05, gamma = 0.05\n",
      "f1_w score = 0.8955926392832938, nu = 0.05, gamma = 0.1\n",
      "f1_w score = 0.9310165549752979, nu = 0.05, gamma = 0.5\n",
      "f1_w score = 0.7991008708054548, nu = 0.1, gamma = 0.01\n",
      "f1_w score = 0.8519725454082029, nu = 0.1, gamma = 0.05\n",
      "f1_w score = 0.8716469802454011, nu = 0.1, gamma = 0.1\n",
      "f1_w score = 0.9096258112690467, nu = 0.1, gamma = 0.5\n",
      "f1_w score = 0.6537408576575479, nu = 0.5, gamma = 0.01\n",
      "f1_w score = 0.6614352295641678, nu = 0.5, gamma = 0.05\n",
      "f1_w score = 0.6798704626734869, nu = 0.5, gamma = 0.1\n",
      "f1_w score = 0.7298615986665591, nu = 0.5, gamma = 0.5\n",
      "best outer f1_w score = 0.9435404188149545\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "f1_w score = 0.8202267239894284, nu = 0.01, gamma = 0.01\n",
      "f1_w score = 0.8676027113273516, nu = 0.01, gamma = 0.05\n",
      "f1_w score = 0.9103120556038934, nu = 0.01, gamma = 0.1\n",
      "f1_w score = 0.9484632181350022, nu = 0.01, gamma = 0.5\n",
      "f1_w score = 0.8053139521617574, nu = 0.05, gamma = 0.01\n",
      "f1_w score = 0.8575523297044001, nu = 0.05, gamma = 0.05\n",
      "f1_w score = 0.8999242075767799, nu = 0.05, gamma = 0.1\n",
      "f1_w score = 0.947216125426076, nu = 0.05, gamma = 0.5\n",
      "f1_w score = 0.7896356897867383, nu = 0.1, gamma = 0.01\n",
      "f1_w score = 0.8456619752532746, nu = 0.1, gamma = 0.05\n",
      "f1_w score = 0.8808805200110407, nu = 0.1, gamma = 0.1\n",
      "f1_w score = 0.9372073271641742, nu = 0.1, gamma = 0.5\n",
      "f1_w score = 0.6597665013665471, nu = 0.5, gamma = 0.01\n",
      "f1_w score = 0.6722919101706119, nu = 0.5, gamma = 0.05\n",
      "f1_w score = 0.7032001782705779, nu = 0.5, gamma = 0.1\n",
      "f1_w score = 0.7304337586048436, nu = 0.5, gamma = 0.5\n",
      "best outer f1_w score = 0.9441323598012811\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "f1_w score = 0.8305120661355733, nu = 0.01, gamma = 0.01\n",
      "f1_w score = 0.8778677805010929, nu = 0.01, gamma = 0.05\n",
      "f1_w score = 0.908577693565419, nu = 0.01, gamma = 0.1\n",
      "f1_w score = 0.9410285986961388, nu = 0.01, gamma = 0.5\n",
      "f1_w score = 0.8164046241939925, nu = 0.05, gamma = 0.01\n",
      "f1_w score = 0.8664673027048879, nu = 0.05, gamma = 0.05\n",
      "f1_w score = 0.8938370210643145, nu = 0.05, gamma = 0.1\n",
      "f1_w score = 0.9354073798975855, nu = 0.05, gamma = 0.5\n",
      "f1_w score = 0.8041077026856928, nu = 0.1, gamma = 0.01\n",
      "f1_w score = 0.8465056645150133, nu = 0.1, gamma = 0.05\n",
      "f1_w score = 0.8759960008793215, nu = 0.1, gamma = 0.1\n",
      "f1_w score = 0.9197315130671642, nu = 0.1, gamma = 0.5\n",
      "f1_w score = 0.659684016710641, nu = 0.5, gamma = 0.01\n",
      "f1_w score = 0.6823101200028482, nu = 0.5, gamma = 0.05\n",
      "f1_w score = 0.7032955115044146, nu = 0.5, gamma = 0.1\n",
      "f1_w score = 0.6974103537907594, nu = 0.5, gamma = 0.5\n",
      "best outer f1_w score = 0.9366656463619343\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "f1_w score = 0.8188001436564452, nu = 0.01, gamma = 0.01\n",
      "f1_w score = 0.8695734115092432, nu = 0.01, gamma = 0.05\n",
      "f1_w score = 0.8985678368137047, nu = 0.01, gamma = 0.1\n",
      "f1_w score = 0.9285393108433172, nu = 0.01, gamma = 0.5\n",
      "f1_w score = 0.8048508416638638, nu = 0.05, gamma = 0.01\n",
      "f1_w score = 0.8497504881119622, nu = 0.05, gamma = 0.05\n",
      "f1_w score = 0.8863296755733553, nu = 0.05, gamma = 0.1\n",
      "f1_w score = 0.9316583035043967, nu = 0.05, gamma = 0.5\n",
      "f1_w score = 0.7933875167130249, nu = 0.1, gamma = 0.01\n",
      "f1_w score = 0.8335042870421566, nu = 0.1, gamma = 0.05\n",
      "f1_w score = 0.8679122840459764, nu = 0.1, gamma = 0.1\n",
      "f1_w score = 0.910964422146391, nu = 0.1, gamma = 0.5\n",
      "f1_w score = 0.6774580733527698, nu = 0.5, gamma = 0.01\n",
      "f1_w score = 0.6983905357793064, nu = 0.5, gamma = 0.05\n",
      "f1_w score = 0.7009259485507563, nu = 0.5, gamma = 0.1\n",
      "f1_w score = 0.7132363714883055, nu = 0.5, gamma = 0.5\n",
      "best outer f1_w score = 0.9292002651713009\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "f1_w score = 0.8225065137385066, nu = 0.01, gamma = 0.01\n",
      "f1_w score = 0.8773324786953461, nu = 0.01, gamma = 0.05\n",
      "f1_w score = 0.9111071039429719, nu = 0.01, gamma = 0.1\n",
      "f1_w score = 0.9328891011731605, nu = 0.01, gamma = 0.5\n",
      "f1_w score = 0.8041960698588745, nu = 0.05, gamma = 0.01\n",
      "f1_w score = 0.8634011953524623, nu = 0.05, gamma = 0.05\n",
      "f1_w score = 0.8963344840237385, nu = 0.05, gamma = 0.1\n",
      "f1_w score = 0.9291343468337516, nu = 0.05, gamma = 0.5\n",
      "f1_w score = 0.7885625206551276, nu = 0.1, gamma = 0.01\n",
      "f1_w score = 0.8447454199689435, nu = 0.1, gamma = 0.05\n",
      "f1_w score = 0.8778529618685372, nu = 0.1, gamma = 0.1\n",
      "f1_w score = 0.902677757652636, nu = 0.1, gamma = 0.5\n",
      "f1_w score = 0.6415380700485442, nu = 0.5, gamma = 0.01\n",
      "f1_w score = 0.6530393724717929, nu = 0.5, gamma = 0.05\n",
      "f1_w score = 0.6805264744323749, nu = 0.5, gamma = 0.1\n",
      "f1_w score = 0.7029612983234891, nu = 0.5, gamma = 0.5\n",
      "best outer f1_w score = 0.9459686185022161\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "f1_w score = 0.8190648309492136, nu = 0.01, gamma = 0.01\n",
      "f1_w score = 0.8688393822990946, nu = 0.01, gamma = 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_w score = 0.9091326725640546, nu = 0.01, gamma = 0.1\n",
      "f1_w score = 0.9447555349698836, nu = 0.01, gamma = 0.5\n",
      "f1_w score = 0.8060130629346787, nu = 0.05, gamma = 0.01\n",
      "f1_w score = 0.8581456592550654, nu = 0.05, gamma = 0.05\n",
      "f1_w score = 0.8950082880687215, nu = 0.05, gamma = 0.1\n",
      "f1_w score = 0.9385191916584116, nu = 0.05, gamma = 0.5\n",
      "f1_w score = 0.7973528960306727, nu = 0.1, gamma = 0.01\n",
      "f1_w score = 0.8383229649305756, nu = 0.1, gamma = 0.05\n",
      "f1_w score = 0.8685208882760806, nu = 0.1, gamma = 0.1\n",
      "f1_w score = 0.920353771290194, nu = 0.1, gamma = 0.5\n",
      "f1_w score = 0.6640106808315428, nu = 0.5, gamma = 0.01\n",
      "f1_w score = 0.6695575915564356, nu = 0.5, gamma = 0.05\n",
      "f1_w score = 0.6895274369992995, nu = 0.5, gamma = 0.1\n",
      "f1_w score = 0.7414233202805525, nu = 0.5, gamma = 0.5\n",
      "best outer f1_w score = 0.9279387352856253\n",
      "\n",
      "x_normal_train shape:  (16131, 150)\n",
      "xfold_test size:  (3226, 150)\n",
      "f1_w score = 0.833179606774715, nu = 0.01, gamma = 0.01\n",
      "f1_w score = 0.8707928587181373, nu = 0.01, gamma = 0.05\n",
      "f1_w score = 0.9085243681694146, nu = 0.01, gamma = 0.1\n",
      "f1_w score = 0.9460202885120186, nu = 0.01, gamma = 0.5\n",
      "f1_w score = 0.8232559009898893, nu = 0.05, gamma = 0.01\n",
      "f1_w score = 0.8550532477693895, nu = 0.05, gamma = 0.05\n",
      "f1_w score = 0.8999726201022666, nu = 0.05, gamma = 0.1\n",
      "f1_w score = 0.9441486066423034, nu = 0.05, gamma = 0.5\n",
      "f1_w score = 0.8033605470511055, nu = 0.1, gamma = 0.01\n",
      "f1_w score = 0.8419279907835957, nu = 0.1, gamma = 0.05\n",
      "f1_w score = 0.875348574039969, nu = 0.1, gamma = 0.1\n",
      "f1_w score = 0.9222862959952652, nu = 0.1, gamma = 0.5\n",
      "f1_w score = 0.6630416438162441, nu = 0.5, gamma = 0.01\n",
      "f1_w score = 0.6753805451533822, nu = 0.5, gamma = 0.05\n",
      "f1_w score = 0.6954407058070637, nu = 0.5, gamma = 0.1\n",
      "f1_w score = 0.7121047726935661, nu = 0.5, gamma = 0.5\n",
      "best outer f1_w score = 0.9391306487355954\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KERNEL</th>\n",
       "      <th>NU</th>\n",
       "      <th>GAMMA</th>\n",
       "      <th>F1_W</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>F1_1</th>\n",
       "      <th>RECALL_0</th>\n",
       "      <th>PRECISION_0</th>\n",
       "      <th>FPR</th>\n",
       "      <th>HYPER_F1_W</th>\n",
       "      <th>SCALER</th>\n",
       "      <th>PCA</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>TRAINING TIME</th>\n",
       "      <th>TESTING TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.923609</td>\n",
       "      <td>0.919870</td>\n",
       "      <td>0.927348</td>\n",
       "      <td>0.874845</td>\n",
       "      <td>0.969780</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>0.946025</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>PCA(n_components=0.99)</td>\n",
       "      <td>OneClassSVM(gamma=0.5, nu=0.01)</td>\n",
       "      <td>60.067633</td>\n",
       "      <td>335.169458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.927939</td>\n",
       "      <td>0.924675</td>\n",
       "      <td>0.931198</td>\n",
       "      <td>0.883375</td>\n",
       "      <td>0.970027</td>\n",
       "      <td>0.029973</td>\n",
       "      <td>0.944756</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>PCA(n_components=0.99)</td>\n",
       "      <td>OneClassSVM(gamma=0.5, nu=0.01)</td>\n",
       "      <td>60.781025</td>\n",
       "      <td>347.141356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.929200</td>\n",
       "      <td>0.926261</td>\n",
       "      <td>0.932143</td>\n",
       "      <td>0.887237</td>\n",
       "      <td>0.968877</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>0.931658</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>PCA(n_components=0.99)</td>\n",
       "      <td>OneClassSVM(gamma=0.5, nu=0.05)</td>\n",
       "      <td>61.292894</td>\n",
       "      <td>263.090907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.933537</td>\n",
       "      <td>0.930655</td>\n",
       "      <td>0.936423</td>\n",
       "      <td>0.889715</td>\n",
       "      <td>0.975543</td>\n",
       "      <td>0.024457</td>\n",
       "      <td>0.941647</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>PCA(n_components=0.99)</td>\n",
       "      <td>OneClassSVM(gamma=0.5, nu=0.01)</td>\n",
       "      <td>60.005532</td>\n",
       "      <td>343.978122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.936666</td>\n",
       "      <td>0.934194</td>\n",
       "      <td>0.939141</td>\n",
       "      <td>0.897150</td>\n",
       "      <td>0.974428</td>\n",
       "      <td>0.025572</td>\n",
       "      <td>0.941029</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>PCA(n_components=0.99)</td>\n",
       "      <td>OneClassSVM(gamma=0.5, nu=0.01)</td>\n",
       "      <td>60.078813</td>\n",
       "      <td>339.800333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.939131</td>\n",
       "      <td>0.936528</td>\n",
       "      <td>0.941736</td>\n",
       "      <td>0.895911</td>\n",
       "      <td>0.981004</td>\n",
       "      <td>0.018996</td>\n",
       "      <td>0.946020</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>PCA(n_components=0.99)</td>\n",
       "      <td>OneClassSVM(gamma=0.5, nu=0.01)</td>\n",
       "      <td>59.626758</td>\n",
       "      <td>339.163272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.939158</td>\n",
       "      <td>0.936856</td>\n",
       "      <td>0.941458</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.974531</td>\n",
       "      <td>0.025469</td>\n",
       "      <td>0.944122</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>PCA(n_components=0.99)</td>\n",
       "      <td>OneClassSVM(gamma=0.5, nu=0.05)</td>\n",
       "      <td>60.204161</td>\n",
       "      <td>256.579804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.943540</td>\n",
       "      <td>0.942001</td>\n",
       "      <td>0.945081</td>\n",
       "      <td>0.915737</td>\n",
       "      <td>0.969816</td>\n",
       "      <td>0.030184</td>\n",
       "      <td>0.938510</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>PCA(n_components=0.99)</td>\n",
       "      <td>OneClassSVM(gamma=0.5, nu=0.01)</td>\n",
       "      <td>61.380809</td>\n",
       "      <td>354.565444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.944132</td>\n",
       "      <td>0.942159</td>\n",
       "      <td>0.946108</td>\n",
       "      <td>0.908302</td>\n",
       "      <td>0.978638</td>\n",
       "      <td>0.021362</td>\n",
       "      <td>0.948463</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>PCA(n_components=0.99)</td>\n",
       "      <td>OneClassSVM(gamma=0.5, nu=0.01)</td>\n",
       "      <td>61.395285</td>\n",
       "      <td>347.955992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.945969</td>\n",
       "      <td>0.943689</td>\n",
       "      <td>0.948245</td>\n",
       "      <td>0.904467</td>\n",
       "      <td>0.986468</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.932889</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>PCA(n_components=0.99)</td>\n",
       "      <td>OneClassSVM(gamma=0.5, nu=0.01)</td>\n",
       "      <td>59.042452</td>\n",
       "      <td>335.317994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  KERNEL    NU  GAMMA      F1_W      F1_0      F1_1  RECALL_0  PRECISION_0  \\\n",
       "0    rbf  0.01    0.5  0.923609  0.919870  0.927348  0.874845     0.969780   \n",
       "8    rbf  0.01    0.5  0.927939  0.924675  0.931198  0.883375     0.970027   \n",
       "6    rbf  0.05    0.5  0.929200  0.926261  0.932143  0.887237     0.968877   \n",
       "1    rbf  0.01    0.5  0.933537  0.930655  0.936423  0.889715     0.975543   \n",
       "5    rbf  0.01    0.5  0.936666  0.934194  0.939141  0.897150     0.974428   \n",
       "9    rbf  0.01    0.5  0.939131  0.936528  0.941736  0.895911     0.981004   \n",
       "2    rbf  0.05    0.5  0.939158  0.936856  0.941458  0.901985     0.974531   \n",
       "3    rbf  0.01    0.5  0.943540  0.942001  0.945081  0.915737     0.969816   \n",
       "4    rbf  0.01    0.5  0.944132  0.942159  0.946108  0.908302     0.978638   \n",
       "7    rbf  0.01    0.5  0.945969  0.943689  0.948245  0.904467     0.986468   \n",
       "\n",
       "        FPR  HYPER_F1_W            SCALER                     PCA  \\\n",
       "0  0.030220    0.946025  StandardScaler()  PCA(n_components=0.99)   \n",
       "8  0.029973    0.944756  StandardScaler()  PCA(n_components=0.99)   \n",
       "6  0.031123    0.931658  StandardScaler()  PCA(n_components=0.99)   \n",
       "1  0.024457    0.941647  StandardScaler()  PCA(n_components=0.99)   \n",
       "5  0.025572    0.941029  StandardScaler()  PCA(n_components=0.99)   \n",
       "9  0.018996    0.946020  StandardScaler()  PCA(n_components=0.99)   \n",
       "2  0.025469    0.944122  StandardScaler()  PCA(n_components=0.99)   \n",
       "3  0.030184    0.938510  StandardScaler()  PCA(n_components=0.99)   \n",
       "4  0.021362    0.948463  StandardScaler()  PCA(n_components=0.99)   \n",
       "7  0.013532    0.932889  StandardScaler()  PCA(n_components=0.99)   \n",
       "\n",
       "                             MODEL  TRAINING TIME  TESTING TIME  \n",
       "0  OneClassSVM(gamma=0.5, nu=0.01)      60.067633    335.169458  \n",
       "8  OneClassSVM(gamma=0.5, nu=0.01)      60.781025    347.141356  \n",
       "6  OneClassSVM(gamma=0.5, nu=0.05)      61.292894    263.090907  \n",
       "1  OneClassSVM(gamma=0.5, nu=0.01)      60.005532    343.978122  \n",
       "5  OneClassSVM(gamma=0.5, nu=0.01)      60.078813    339.800333  \n",
       "9  OneClassSVM(gamma=0.5, nu=0.01)      59.626758    339.163272  \n",
       "2  OneClassSVM(gamma=0.5, nu=0.05)      60.204161    256.579804  \n",
       "3  OneClassSVM(gamma=0.5, nu=0.01)      61.380809    354.565444  \n",
       "4  OneClassSVM(gamma=0.5, nu=0.01)      61.395285    347.955992  \n",
       "7  OneClassSVM(gamma=0.5, nu=0.01)      59.042452    335.317994  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocsvm_params = {\n",
    "    'KERNEL' : 'rbf',    \n",
    "    'NU'     : [0.01, 0.05, 0.1, 0.5],\n",
    "    'GAMMA'  : [0.01, 0.05, 0.1, 0.5],   \n",
    "}\n",
    "\n",
    "#outer_metrics\n",
    "test_metrics = classic_cross_val(model=\"ocsvm\", params=ocsvm_params, apply_std=True, apply_minmax=False,\n",
    "                                dim_red=\"pca\", n_folds=10)   \n",
    "\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62805061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  KERNEL    NU  GAMMA      F1_W      F1_0      F1_1  RECALL_0  PRECISION_0  \\\n",
      "0    rbf  0.01    0.5  0.923609  0.919870  0.927348  0.874845     0.969780   \n",
      "8    rbf  0.01    0.5  0.927939  0.924675  0.931198  0.883375     0.970027   \n",
      "6    rbf  0.05    0.5  0.929200  0.926261  0.932143  0.887237     0.968877   \n",
      "1    rbf  0.01    0.5  0.933537  0.930655  0.936423  0.889715     0.975543   \n",
      "5    rbf  0.01    0.5  0.936666  0.934194  0.939141  0.897150     0.974428   \n",
      "9    rbf  0.01    0.5  0.939131  0.936528  0.941736  0.895911     0.981004   \n",
      "2    rbf  0.05    0.5  0.939158  0.936856  0.941458  0.901985     0.974531   \n",
      "3    rbf  0.01    0.5  0.943540  0.942001  0.945081  0.915737     0.969816   \n",
      "4    rbf  0.01    0.5  0.944132  0.942159  0.946108  0.908302     0.978638   \n",
      "7    rbf  0.01    0.5  0.945969  0.943689  0.948245  0.904467     0.986468   \n",
      "\n",
      "        FPR  HYPER_F1_W            SCALER                     PCA  \\\n",
      "0  0.030220    0.946025  StandardScaler()  PCA(n_components=0.99)   \n",
      "8  0.029973    0.944756  StandardScaler()  PCA(n_components=0.99)   \n",
      "6  0.031123    0.931658  StandardScaler()  PCA(n_components=0.99)   \n",
      "1  0.024457    0.941647  StandardScaler()  PCA(n_components=0.99)   \n",
      "5  0.025572    0.941029  StandardScaler()  PCA(n_components=0.99)   \n",
      "9  0.018996    0.946020  StandardScaler()  PCA(n_components=0.99)   \n",
      "2  0.025469    0.944122  StandardScaler()  PCA(n_components=0.99)   \n",
      "3  0.030184    0.938510  StandardScaler()  PCA(n_components=0.99)   \n",
      "4  0.021362    0.948463  StandardScaler()  PCA(n_components=0.99)   \n",
      "7  0.013532    0.932889  StandardScaler()  PCA(n_components=0.99)   \n",
      "\n",
      "                             MODEL  TRAINING TIME  TESTING TIME  \n",
      "0  OneClassSVM(gamma=0.5, nu=0.01)      60.067633    335.169458  \n",
      "8  OneClassSVM(gamma=0.5, nu=0.01)      60.781025    347.141356  \n",
      "6  OneClassSVM(gamma=0.5, nu=0.05)      61.292894    263.090907  \n",
      "1  OneClassSVM(gamma=0.5, nu=0.01)      60.005532    343.978122  \n",
      "5  OneClassSVM(gamma=0.5, nu=0.01)      60.078813    339.800333  \n",
      "9  OneClassSVM(gamma=0.5, nu=0.01)      59.626758    339.163272  \n",
      "2  OneClassSVM(gamma=0.5, nu=0.05)      60.204161    256.579804  \n",
      "3  OneClassSVM(gamma=0.5, nu=0.01)      61.380809    354.565444  \n",
      "4  OneClassSVM(gamma=0.5, nu=0.01)      61.395285    347.955992  \n",
      "7  OneClassSVM(gamma=0.5, nu=0.01)      59.042452    335.317994  \n",
      "0.9362880575950558\n",
      "  KERNEL    NU  GAMMA      F1_W      F1_0      F1_1  RECALL_0  PRECISION_0  \\\n",
      "0    rbf  0.01    0.5  0.923609  0.919870  0.927348  0.874845     0.969780   \n",
      "8    rbf  0.01    0.5  0.927939  0.924675  0.931198  0.883375     0.970027   \n",
      "6    rbf  0.05    0.5  0.929200  0.926261  0.932143  0.887237     0.968877   \n",
      "1    rbf  0.01    0.5  0.933537  0.930655  0.936423  0.889715     0.975543   \n",
      "5    rbf  0.01    0.5  0.936666  0.934194  0.939141  0.897150     0.974428   \n",
      "9    rbf  0.01    0.5  0.939131  0.936528  0.941736  0.895911     0.981004   \n",
      "2    rbf  0.05    0.5  0.939158  0.936856  0.941458  0.901985     0.974531   \n",
      "3    rbf  0.01    0.5  0.943540  0.942001  0.945081  0.915737     0.969816   \n",
      "4    rbf  0.01    0.5  0.944132  0.942159  0.946108  0.908302     0.978638   \n",
      "7    rbf  0.01    0.5  0.945969  0.943689  0.948245  0.904467     0.986468   \n",
      "\n",
      "        FPR  HYPER_F1_W            SCALER                     PCA  \\\n",
      "0  0.030220    0.946025  StandardScaler()  PCA(n_components=0.99)   \n",
      "8  0.029973    0.944756  StandardScaler()  PCA(n_components=0.99)   \n",
      "6  0.031123    0.931658  StandardScaler()  PCA(n_components=0.99)   \n",
      "1  0.024457    0.941647  StandardScaler()  PCA(n_components=0.99)   \n",
      "5  0.025572    0.941029  StandardScaler()  PCA(n_components=0.99)   \n",
      "9  0.018996    0.946020  StandardScaler()  PCA(n_components=0.99)   \n",
      "2  0.025469    0.944122  StandardScaler()  PCA(n_components=0.99)   \n",
      "3  0.030184    0.938510  StandardScaler()  PCA(n_components=0.99)   \n",
      "4  0.021362    0.948463  StandardScaler()  PCA(n_components=0.99)   \n",
      "7  0.013532    0.932889  StandardScaler()  PCA(n_components=0.99)   \n",
      "\n",
      "                             MODEL  TRAINING TIME  TESTING TIME  \n",
      "0  OneClassSVM(gamma=0.5, nu=0.01)      60.067633    335.169458  \n",
      "8  OneClassSVM(gamma=0.5, nu=0.01)      60.781025    347.141356  \n",
      "6  OneClassSVM(gamma=0.5, nu=0.05)      61.292894    263.090907  \n",
      "1  OneClassSVM(gamma=0.5, nu=0.01)      60.005532    343.978122  \n",
      "5  OneClassSVM(gamma=0.5, nu=0.01)      60.078813    339.800333  \n",
      "9  OneClassSVM(gamma=0.5, nu=0.01)      59.626758    339.163272  \n",
      "2  OneClassSVM(gamma=0.5, nu=0.05)      60.204161    256.579804  \n",
      "3  OneClassSVM(gamma=0.5, nu=0.01)      61.380809    354.565444  \n",
      "4  OneClassSVM(gamma=0.5, nu=0.01)      61.395285    347.955992  \n",
      "7  OneClassSVM(gamma=0.5, nu=0.01)      59.042452    335.317994  \n",
      "Average F1 Score: 0.9362880575950558 +/- 0.004677445287011039\n",
      "Average FPR: 0.02508866396259436 +/- 0.0035658847905241406\n",
      "Average Training Time: 60.387536057730834 +/- 0.49505605463094804\n",
      "Average Testing Time\": 326.27626820310365 +/- 22.038145817458567\n"
     ]
    }
   ],
   "source": [
    "avg_f1w, conf_interval, average_fpr, confidence_int_fpr, average_training_time, confidence_int_training_time, average_testing_time, confidence_int_testing_time = confidence_interval(test_metrics, 0.95)\n",
    "print(avg_f1w)\n",
    "\n",
    "average_f1score, confidence_int_f1_score, average_fpr, confidence_int_fpr, average_training_time, confidence_int_training_time, average_testing_time, confidence_int_testing_time = confidence_interval(test_metrics, 0.95)\n",
    "print(f'Average F1 Score: {average_f1score} +/- {confidence_int_f1_score}')\n",
    "print(f'Average FPR: {average_fpr} +/- {confidence_int_fpr}')\n",
    "print(f'Average Training Time: {average_training_time} +/- {confidence_int_training_time}')\n",
    "print(f'Average Testing Time\": {average_testing_time} +/- {confidence_int_testing_time}') # 7 7 7 7 7 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d17688",
   "metadata": {},
   "source": [
    "### Test Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d43cd078",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score Weighted in Test Set:  0.9442724458204333\n",
      "False Positive Rate in Test set:  0.0\n"
     ]
    }
   ],
   "source": [
    "best_scaler = test_metrics.iloc[-1]['SCALER']\n",
    "best_pca = test_metrics.iloc[-1]['PCA']\n",
    "best_model = test_metrics.iloc[-1]['MODEL']\n",
    "\n",
    "#scale data\n",
    "x_test_scaled = best_scaler.transform(x_test)\n",
    "\n",
    "# apply pca to dataz\n",
    "x_test_pca = best_pca.transform(x_test_scaled) #:q \n",
    "#x_test_pca = x_test_scaled\n",
    "\n",
    "# test best model with best parameters\n",
    "prediction = [1 if i == -1 else 0 for i in best_model.predict(x_test_pca)] #score_samples  scores =      \n",
    "#\n",
    "f1_w, f1_0, f1_1, recall_0, precision_0, FPR2 = get_test_metrics(y_test, prediction)\n",
    "\n",
    "print(\"F1 Score Weighted in Test Set: \", f1_w)    \n",
    "print(\"False Positive Rate in Test set: \", FPR2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
